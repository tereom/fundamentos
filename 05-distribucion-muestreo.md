# Estimaci√≥n y distribuci√≥n de muestreo



En esta secci√≥n discutiremos cu√°l el objetivo general del proceso de estimaci√≥n.
y c√≥mo entender y manejar la variabilidad que se produce cuando aleatorizamos
la selecci√≥n de las muestras que utilizamos para hacer an√°lisis.


## Ejemplo: precios de casas {-}

Supongamos que queremos conocer el valor total de las casas
que se vendieron recientemente en una zona
particular. Supondremos que tenemos un listado de las casas que se han
vendido recientemente, pero en ese listado no se encuentra el precio de venta.
Decidimos entonces tomar una muestra aleatoria de 100 de esas casas. Para esas
casas hacemos trabajo de campo para averiguar el precio de venta.


```r
marco_casas <- read_csv("data/casas.csv")
set.seed(841)
muestra_casas <- sample_n(marco_casas, 100) %>%
  select(id, nombre_zona, area_habitable_sup_m2, precio_miles)
sprintf("Hay %0.0f casas en total, tomamos muestra de %0.0f",
        nrow(marco_casas), nrow(muestra_casas))
```

```
## [1] "Hay 1144 casas en total, tomamos muestra de 100"
```

```r
head(muestra_casas)
```

```
## [90m# A tibble: 6 x 4[39m
##      id nombre_zona area_habitable_sup_m2 precio_miles
##   [3m[90m<dbl>[39m[23m [3m[90m<chr>[39m[23m                       [3m[90m<dbl>[39m[23m        [3m[90m<dbl>[39m[23m
## [90m1[39m   287 NAmes                       161.          159 
## [90m2[39m   755 NAmes                        95.3         156 
## [90m3[39m  [4m1[24m190 Gilbert                     168.          189 
## [90m4[39m    36 NridgHt                     228.          309 
## [90m5[39m    32 Sawyer                      114.          149.
## [90m6[39m   538 NAmes                        80.3         111.
```
Como tomamos una muestra aleatoria, intentamos estimar el valor
total de las casas que se vendieron expandiendo el total muestral, es decir
nuestro estimador $\hat{t} = t(X_1,\ldots X_{100})$ del total
poblacional $t$ es

$$\hat{t} = \frac{N}{n} \sum_{i=1}^{100} X_i = N\bar{x}$$
Esta funci√≥n implementa el estimador:


```r
n <- nrow(muestra_casas) # tama√±o muestra
N <- nrow(marco_casas) # tama√±o poblaci√≥n
estimar_total <- function(muestra_casas, N){
  total_muestral <- sum(muestra_casas$precio_miles)
  n <- nrow(muestra_casas)
  # cada unidad de la muestra representa a N/n
  f_exp <- N / n
  # estimador total es la expansi√≥n del total muestral
  estimador_total <- f_exp * total_muestral
  res <- tibble(total_muestra = total_muestral,
         factor_exp = f_exp,
         est_total_millones = estimador_total / 1000)
  res
}
estimar_total(muestra_casas, N) %>%
  mutate(across(where(is.numeric), round, 2))
```

```
## [90m# A tibble: 1 x 3[39m
##   total_muestra factor_exp est_total_millones
##           [3m[90m<dbl>[39m[23m      [3m[90m<dbl>[39m[23m              [3m[90m<dbl>[39m[23m
## [90m1[39m        [4m1[24m[4m8[24m444.       11.4                211
```

Sin embargo, si hubi√©ramos obtenido otra muestra, hubi√©ramos obtenido otra
estimaci√≥n diferente. Por ejemplo:


```r
estimar_total(sample_n(marco_casas, 100), N) %>%
  mutate(across(where(is.numeric), round, 2))
```

```
## [90m# A tibble: 1 x 3[39m
##   total_muestra factor_exp est_total_millones
##           [3m[90m<dbl>[39m[23m      [3m[90m<dbl>[39m[23m              [3m[90m<dbl>[39m[23m
## [90m1[39m        [4m1[24m[4m7[24m916.       11.4               205.
```

El valor poblacional que buscamos estimar (n√≥tese que en la pr√°ctica este no lo conocemos)
es:


```r
# multiplicar por 1000 para que sea en millones de d√≥lares
total_pob <- sum(marco_casas %>% pull(precio_miles)) / 1000
total_pob
```

```
## [1] 209.7633
```

As√≠ que:

- Para algunas muestras esta estad√≠stica puede estar muy cercana al valor poblacional,
pero para otras puede estar m√°s lejana.
- Para entender qu√© tan buena es una estimaci√≥n
particular, entonces, tenemos que entender *cu√°nta variabilidad hay de muestra a muestra*
debida a la aleatorizaci√≥n. Esto depende del dise√±o de la muestra y
de la poblaci√≥n de precios de casas (que no conocemos).

## Distribuci√≥n de muestreo {-}

La distribuci√≥n de muestreo de una estad√≠stica enumera los posibles resultados
que puede tomar esa estad√≠stica sobre todas las muestras posibles. Este es el concepto
b√°sico para poder entender qu√© tan bien o mal estima un par√°metro poblacional dado.

En nuestro ejemplo anterior de precio de casas, no podemos calcular todas las posibles
estimaciones bajo todas las posibles muestras, pero podemos aproximar
repitiendo una gran cantidad de veces el proceso de muestreo, como hicimos
al aproximar la distribuci√≥n de permutaciones de estad√≠sticas de prueba de las
secciones anteriores.

Empezamos repitiendo 10 veces y examinamos c√≥mo var√≠a nuestra estad√≠stica:


```r
replicar_muestreo <- function(marco_casas, m = 500, n){
  # n es el tama√±o de muestra que se saca de marco_casas
  # m es el n√∫mero de veces que repetimos el muestro de tama√±o n
  resultados <- map(1:m,
      function(id) {
        sample_n(marco_casas, n) %>%
          estimar_total(N) %>%
          mutate(id_muestra = id) %>%
          select(id_muestra, everything())
      })
  resultados %>% bind_rows
}
replicar_muestreo(marco_casas, m = 10, n = 100) %>%
  mutate(across(where(is.numeric), round, 1)) %>%
  formatear_tabla()
```



| id_muestra| total_muestra| factor_exp| est_total_millones|
|----------:|-------------:|----------:|------------------:|
|          1|       17594.8|       11.4|              201.3|
|          2|       17423.9|       11.4|              199.3|
|          3|       18444.3|       11.4|              211.0|
|          4|       17696.6|       11.4|              202.4|
|          5|       17275.8|       11.4|              197.6|
|          6|       17867.6|       11.4|              204.4|
|          7|       18450.8|       11.4|              211.1|
|          8|       18187.2|       11.4|              208.1|
|          9|       18604.2|       11.4|              212.8|
|         10|       19144.4|       11.4|              219.0|
Como vemos, hay variaci√≥n considerable en nuestro estimador del total, pero
la estimaci√≥n que har√≠amos con cualquiera de estas muestras no es muy mala. Ahora
examinamos un n√∫mero m√°s grande de simulaciones:


```r
replicaciones_1 <- replicar_muestreo(marco_casas, m = 1500, n = 100)
```

Y el siguiente histograma nos dice qu√© podemos esperar de la variaci√≥n de
nuestras estimadores, y donde es m√°s probable que una estimaci√≥n particular caiga:


```r
graf_1 <- ggplot(replicaciones_1, aes(x = est_total_millones)) +
  geom_histogram() +
  geom_vline(xintercept = total_pob, colour = "red") +
  xlab("Millones de d√≥lares") +
  scale_x_continuous(breaks = seq(180, 240, 10), limits = c(180, 240))
graf_1
```

<img src="05-distribucion-muestreo_files/figure-html/unnamed-chunk-7-1.png" width="672" style="display: block; margin: auto;" />
Con muy alta probabilidad  el error no ser√° de m√°s de unos 30 millones de d√≥lares
(o no m√°s de 20% del valor poblacional).



<div class="mathblock">
<p><strong>Definici√≥n</strong> Sea <span class="math inline">\(X_1, X_2, \ldots X_n\)</span> una muestra, y <span class="math inline">\(T = t(X_1, X_2, \ldots, X_n)\)</span> una estad√≠stica.</p>
<p>La <strong>distribuci√≥n de muestreo</strong> de <span class="math inline">\(T\)</span> es la funci√≥n de distribuci√≥n de <span class="math inline">\(T\)</span>. Esta distribuci√≥n es sobre todas las posibles muestras que se pueden obtener.</p>
<p>Cuando usamos <span class="math inline">\(T\)</span> para estimar alg√∫n par√°metro poblacional <span class="math inline">\(\theta\)</span>, decimos informalmente que el estimador es <strong>preciso</strong> si su distribuci√≥n de muestreo est√° muy concentrada alrededor del valor <span class="math inline">\(\theta\)</span> que queremos estimar.</p>
</div>

Si la distribuci√≥n de muestreo est√° concentrada en un conjunto muy grande
o muy disperso, quiere decir que con alta probabilidad cuando obtengamos
nuestra muestra y calculemos nuestra estimaci√≥n, el resultado estar√° lejano
del valor poblacional que nos interesa estimar.

Veamos qu√© pasa cuando hacemos la muestra m√°s grande en nuestro ejemplo:


```r
replicaciones_2 <- replicar_muestreo(marco_casas, m = 1500, n = 250)
```

Graficamos las dos distribuciones de muestreo juntas, y vemos c√≥mo
con mayor muestra obtenemos un estimador m√°s preciso, y sin considerar el costo,
preferimos el estimador **mejor concentrado alrededor del valor que buscamos estimar**.


```r
library(patchwork)
graf_2 <- ggplot(replicaciones_2, aes(x = est_total_millones)) +
  geom_histogram() +
  geom_vline(xintercept = total_pob, colour = "red") +
  xlab("Millones de d√≥lares") +
  scale_x_continuous(breaks = seq(180, 240, 10), limits = c(180, 240))
graf_1 + graf_2
```

<img src="05-distribucion-muestreo_files/figure-html/unnamed-chunk-10-1.png" width="768" style="display: block; margin: auto;" />

<div class="comentario">
<p><strong>Observaci√≥n</strong>: a veces este concepto se confunde la distribuci√≥n poblacional de las <span class="math inline">\(X_i\)</span>. Esto es muy diferente. Por ejemplo, en nuestro caso, el histograma de la distribuci√≥n de valores poblacionales es</p>
</div>


```r
ggplot(marco_casas, aes(x = precio_miles)) + geom_histogram()
```

<img src="05-distribucion-muestreo_files/figure-html/unnamed-chunk-12-1.png" width="480" style="display: block; margin: auto;" />
que en general no tiene ver mucho en escala o forma con la distribuci√≥n de muestreo
de nuestro estimador del total.

## M√°s ejemplos {-}

Podemos tambi√©n considerar muestrear de poblaciones sint√©ticas o modelos
probabil√≠sticos que usamos para modelar poblaciones reales.

Por ejemplo, supongamos que tomamos una muestra de tama√±o 15 de la distribuci√≥n
uniforme en $[0,1]$. Es decir, cada $X_i$ es un valor uniformemente distribuido
en $[0,1]$, y las $X_i$ se extraen independientemente unas de otras. Consideramos
dos estad√≠sticas de inter√©s:

1. La media muestral $T_1(X) = \frac{1}{n}\sum_{i = 1}{15} X_i$
2. El cuantil 0.75 de la muestra $T_2(X) = q_{0.75}(X)$

\BeginKnitrBlock{ejercicio}<div class="ejercicio">¬øC√≥mo crees que se vean las distribuciones muestrales de estas estad√≠sticas?
  ¬øAlrededor de qu√© valores crees que concentren? ¬øCrees que tendr√°n mucha o poca
dispersi√≥n? ¬øQu√© forma crees que tengan?</div>\EndKnitrBlock{ejercicio}

Para el primer caso hacemos:


```r
# simular
replicar_muestreo_unif <- function(est = estimador_1, m, n = 15){
  valores_est <- map_dbl(1:m, ~ est(runif(n)))
  tibble(id_muestra = 1:m, estimacion = valores_est)
}
sim_estimador_1 <- replicar_muestreo_unif(mean, 4000, 15)
# graficar aprox de distribuci√≥n de muestreo
ggplot(sim_estimador_1, aes(x = estimacion)) +
  geom_histogram(bins = 40) +
  xlim(c(0, 1))
```

<img src="05-distribucion-muestreo_files/figure-html/unnamed-chunk-14-1.png" width="672" style="display: block; margin: auto;" />


```r
# simular para el m√°ximo
cuantil_75 <- function(x) quantile(x, 0.75)
sim_estimador_2 <- replicar_muestreo_unif(cuantil_75, 4000, 15)
# graficar distribuci√≥n de muestreo
ggplot(sim_estimador_2, aes(x = estimacion)) +
  geom_histogram(breaks = seq(0, 1, 0.02)) +
  xlim(c(0, 1))
```

<img src="05-distribucion-muestreo_files/figure-html/unnamed-chunk-15-1.png" width="672" style="display: block; margin: auto;" />


\BeginKnitrBlock{ejercicio}<div class="ejercicio">Sup√≥n que tenemos una muestra de 30 observaciones de una distribuci√≥n
uniforme $[0,b]$.

- ¬øQu√© tan buen estimador de $b/2$ es la media muestral? ¬øC√≥mo lo cuantificar√≠as?
- ¬øQu√© tan buen estimador del cuantil 0.8 de la distribuci√≥n uniforme es
el cuantil 0.8 muestral? ¬øQu√© desventajas notas en este estimador?
</div>\EndKnitrBlock{ejercicio}

## El error est√°ndar {-}

Una primera medida √∫til de la dispersi√≥n de la distribuci√≥n de muestreo
es su desviaci√≥n est√°ndar: la raz√≥n espec√≠fica tiene qu√© ver
con un resultado importante, el teorema central del l√≠mite, que veremos
m√°s adelante. En este caso particular, a esta desviaci√≥n est√°ndar
se le llama error est√°ndar:

<div class="mathblock">
<p><strong>Definici√≥n</strong> A la desviaci√≥n est√°ndar de una estad√≠stica <span class="math inline">\(T\)</span> le llamamos su <strong>error est√°ndar</strong>, y la denotamos por <span class="math inline">\(\text{ee}(T)\)</span>. A cualquier estimador de este error est√°ndar lo denotamos como <span class="math inline">\(\hat{\text{ee}}(T)\)</span>.</p>
</div>

Este error est√°ndar mide qu√© tanto var√≠a el estimador $T$ de muestra a muestra.

**Observaci√≥n**: es importante no confundir el error est√°ndar con
la desviaci√≥n est√°ndar de una muestra (o de la poblaci√≥n).


En nuestro ejemplo
de las uniformes, la desviaci√≥n est√°ndar de las muestras var√≠a como:


```r
map_dbl(1:10000, ~ sd(runif(15))) %>% quantile %>% round(2)
```

```
##   0%  25%  50%  75% 100% 
## 0.11 0.26 0.29 0.31 0.41
```

Mientras que el error est√°ndar de la media es aproximadamente


```r
map_dbl(1:10000, ~ mean(runif(15))) %>% sd
```

```
## [1] 0.07439575
```

y el error est√°ndar del m√°ximo es aproximadamente


```r
map_dbl(1:10000, ~ max(runif(15))) %>% sd
```

```
## [1] 0.05928675
```

\BeginKnitrBlock{ejercicio}<div class="ejercicio">Como ejercicio para contrastar estos conceptos,
puedes considerar: ¬øQu√© pasa con la desviaci√≥n est√°ndar de una muestra muy grande de uniformes? ¬øQu√© pasa con el error est√°ndar de la media muestral de una muestra muy grande de uniformes?</div>\EndKnitrBlock{ejercicio}



### Ejemplo: valor de casas {-}

Consideramos el error est√°ndar del estimador del total del inventario vendido, usando
una muestra de 250 con el estimador del total que consideramos. Como aproximamos con
simulaci√≥n la distribuci√≥n de muestreo, podemos hacer:


```r
ee_2 <- replicaciones_2 %>% pull(est_total_millones) %>% sd
round(ee_2, 1)
```

```
## [1] 5.2
```
que est√° en millones de pesos y cuantifica la dispersi√≥n de la distribuci√≥n de
muestreo del estimador del total.

Para tama√±o de muestra 100, obtenemos m√°s dispersi√≥n:


```r
ee_1 <- replicaciones_1 %>% pull(est_total_millones) %>% sd
round(ee_1, 1)
```

```
## [1] 8.9
```

N√≥tese que esto es muy diferente, por ejemplo, a la desviaci√≥n est√°ndar
poblacional o de una muestra. Estas dos cantidades miden la variabilidad del
estimador del total.

## Calculando la distribuci√≥n de muestreo {-}

En los ejemplos anteriores usamos simulaci√≥n para obtener aproximaciones
de la distribuci√≥n de muestreo de algunos estimadores. Tambi√©n
es posible

- Hacer c√°lculos exactos a partir de modelos
probabil√≠sticos.
- Hacer aproximaciones asint√≥ticas para muestras grandes (de las cuales
la m√°s importante es la que da el teorema central del l√≠mite).

En los ejemplos de arriba, cuando muestreamos de la poblaciones,
extrajimos las muestras de manera aproximadamente independiente. Cada
observaci√≥n $X_i$ tiene la misma distribuci√≥n y las $X_i$'s son
independientes. Este tipo de dise√±os aleatorizados es de los m√°s
simples, y  se llama **muestreo aleatorio simple**.

En general, en esta parte haremos siempre este supuesto: Una **muestra**
es iid (independiente e id√©nticamente distribuida) si es
es un conjunto de observaciones $X_1,X_2, \ldots X_n$ independientes,
y cada una con la misma distribuci√≥n.

En t√©rminos de poblaciones, esto lo logramos obteniendo cada observaci√≥n
de manera aleatoria con el mismo procedimiento. En t√©rminos de modelos
probabil√≠sticos, cada $X_i$ se extrae de la misma distribuci√≥n fija $F(x)$
(que pensamos como la "poblaci√≥n") de manera independiente.


### Ejemplo {-}

Si $X_1, X_2, \ldots X_n$ es una muestra de uniformes independientes en $[0,1]$, ¬øc√≥mo
calcular√≠amos la distribuci√≥n de muestreo del m√°ximo muestra $T_2 = \max$? En este
caso, es f√°cil calcular su funci√≥n de distribuci√≥n acumulada de manera exacta:

$$F_{\max}(x) = P(\max\{X_1,X_2,\ldots X_n\} \leq x)$$
El m√°ximo es menor o igual a $x$ si y s√≥lo si todas las $X_i$ son menores
o iguales a $x$, as√≠ que
$$F_\max (x) = P(X_1\leq x, X_2\leq x, \cdots, X_n\leq x)$$
como las $X_i$'s son independientes entonces
$$F_\max(x) = P(X_1\leq x)P(X_2\leq x)\cdots P(X_n\leq x) = x^n$$
para $x\in [0,1]$, pues para cada $X_i$ tenemos $P(X_i\leq x) = x$ (demu√©stralo).
As√≠ que no es necesario usar simulaci√≥n para conocer esta distribuci√≥n de muestreo.
Derivando esta distribuci√≥n acumulada obtenemos su densidad, que es

$$f(x) = nx^{n-1}$$

para $x\in [0,1]$, y es cero en otro caso.

Si comparamos con nuestra simulaci√≥n:


```r
teorica <- tibble(x = seq(0, 1 ,0.001)) %>%
  mutate(f_dens = 15 * x^14)
sim_estimador_3 <- replicar_muestreo_unif(max, 4000, 15)
ggplot(sim_estimador_3) +
  geom_histogram(aes(x = estimacion), breaks = seq(0, 1, 0.02)) +
  xlim(c(0.5, 1)) +
  # el histograma es de ancho 0.02 y el n√∫mero de simulaciones 4000  
  geom_line(data = teorica, aes(x = x, y = (4000 * 0.02) * f_dens),
            colour = "red", size = 1.3)
```

<img src="05-distribucion-muestreo_files/figure-html/unnamed-chunk-24-1.png" width="672" style="display: block; margin: auto;" />
Y vemos que con la simulaci√≥n obtuvimos una buena aproximaci√≥n


**Nota**: ¬øc√≥mo se relaciona un histograma con la funci√≥n de densidad
que genera los datos? Sup√≥n que $f(x)$ es una funci√≥n de densidad, y
obtenemos un n√∫mero $N$ de simulaciones independientes. Si escogemos
un histograma de ancho $\Delta$, ¬øcu√°ntas observaciones esperamos
que caigan en un intervalo $I = [a - \Delta/2, a + \Delta/2]$?. La probabilidad
de que una observaci√≥n caiga en $I$ es igual a

$$P(X\in I) = \int_I f(x)\,dx = \int_{a - \Delta/2}^{a + \Delta/2} f(x)\,dx \approx f(a)long(I) = f(a) \Delta$$
para $\Delta$ chica. Si nuestra muestra es de tama√±o $N$, el n√∫mero esperado
de observaciones que caen en $I$ es entonces $Nf(a)\Delta$. Eso explica
el ajuste que hicimos en la gr√°fica de arriba. Otra manera de hacer es
ajustando el histograma: si en un intervalo el histograma alcanza el valor $y$,
$$f(a) = \frac{y}{N\Delta}$$


```r
teorica <- tibble(x = seq(0, 1 ,0.001)) %>%
  mutate(f_dens = 15*x^{14})
ggplot(sim_estimador_3) +
  geom_histogram(aes(x = estimacion, y = ..density..), breaks = seq(0, 1, 0.02)) +
  xlim(c(0.5, 1)) +
  # el histograma es de ancho 0.02 y el n√∫mero de simulaciones 4000  
  geom_line(data = teorica, aes(x = x, y = f_dens),
            colour = "red", size = 1.3)
```

<img src="05-distribucion-muestreo_files/figure-html/unnamed-chunk-25-1.png" width="672" style="display: block; margin: auto;" />

### Ejemplo {-}

Supongamos que las $X_i$'s son independientes y exponenciales con tasa $\lambda > 0$.
¬øCu√°l es la distribuci√≥n de muestreo de la suma $S$? Sabemos que la suma
de exponenciales independientes es una distribuci√≥n gamma con par√°metros $(n, \lambda)$,
y esta es la distribuci√≥n de muestreo de nuestra estad√≠stica $S$ bajo las hip√≥tesis
que hicimos.

Podemos checar este resultado con simulaci√≥n, por ejemplo para una
muestra de tama√±o $n=15$ con $\lambda = 1$:


```r
replicar_muestreo_exp <- function(est = estimador_1, m, n = 15, lambda = 1){
  valores_est <- map_dbl(1:m, ~ est(rexp(n, lambda)))
  tibble(id_muestra = 1:m, estimacion = valores_est)
}
sim_estimador_1 <- replicar_muestreo_exp(sum, 4000, n = 15)
teorica <- tibble(x = seq(0, 35, 0.001)) %>%
  mutate(f_dens = dgamma(x, shape = 15, rate = 1))
# graficar aprox de distribuci√≥n de muestreo
ggplot(sim_estimador_1) +
  geom_histogram(aes(x = estimacion, y = ..density..), bins = 40) +
  geom_line(data = teorica, aes(x = x, y = f_dens), colour = "red", size = 1.2)
```

<img src="05-distribucion-muestreo_files/figure-html/unnamed-chunk-26-1.png" width="672" style="display: block; margin: auto;" />

## Teorema central del l√≠mite {-}

Si consideramos los ejemplos de arriba donde consideramos estimadores
basados en una suma o total o en una media (y en menor medida cuantiles muestrales ?),
vimos que las distribuci√≥n de
muestreo estad√≠sticas que usamos tienden a tener una forma com√∫n de campana.
Estas son manifestaciones de una regularidad estad√≠stica importante que
se establece en el **teorema central del l√≠mite**: las distribuciones de muestreo
de sumas y promedios son aproximadamente normales cuando el tama√±o de muestra
es suficientemente grande.

\BeginKnitrBlock{mathblock}<div class="mathblock">**Teorema central del l√≠mite**
 
  Si $X_1,X_2, \ldots, X_n$ son independientes e id√©nticamente distribuidas con
media $\mu$ y desviaci√≥n est√°ndar $\sigma$ finitas.

Si el tama√±o de muestra $n$ es grande,  entonces la distribuci√≥n de muestreo de la media $\bar{X}$ es aproximadamente normal con media $\mu$ y desviaci√≥n est√°ndar $\sigma/\sqrt{n}$,
que escribimos como

$$\bar{X} \xrightarrow{} N \left (\mu, \frac{\sigma}{\sqrt{n}} \right)$$

Adicionalmente, la distribuci√≥n de la
media estandarizada converge a una distribuci√≥n normal
est√°ndar cuando $n$ es grande:
$$\frac{\bar{X}-\mu}{\sigma} \xrightarrow{}  N(0, 1)$$
</div>\EndKnitrBlock{mathblock}

- El error est√°ndar de $\bar{X}$ es
$\text{ee}(\bar{X}) = \frac{\sigma}{\sqrt{n}}$. Si tenemos una muestra, podemos
estimar $\sigma$ con de la siguiente forma:
$$\hat{\sigma} =\sqrt{\frac{1}{n}\sum_{i=1}^n (X_i - \bar{X})^2}$$
o el m√°s com√∫n (que explicaremos m√°s adelante)
$$\hat{s} = \sqrt{\frac{1}{n-1}\sum_{i=1}^n (X_i - \bar{X})^2}$$

- Este hecho junto con el teorema del l√≠mite central nos dice cu√°l es la dispersi√≥n,
y c√≥mo se distribuyen las posibles desviaciones de la media muestral alrededor
de la verdadera media poblacional.

- ¬øQu√© tan grande debe ser $n$. Depende de c√≥mo es la poblaci√≥n. Cuando la poblaci√≥n
tiene una distribuci√≥n muy sesgada, por ejemplo, $n$ t√≠picamente
necesita ser m√°s grande que cuando la poblaci√≥n es sim√©trica si queremos
obtener una aproximaci√≥n "buena".

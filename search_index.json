[
["index.html", "EST-46111: Fundamentos de Estad√≠stica con Remuestreo Informaci√≥n del curso Temario Evaluaci√≥n", " EST-46111: Fundamentos de Estad√≠stica con Remuestreo Teresa Ortiz (001), Alfredo Garbuno (002), Felipe Gonz√°lez Informaci√≥n del curso Notas del curso Fundamentos de Estad√≠stica con Remuestreo del programa de maestr√≠a en Ciencia de Datos del ITAM. En caso de encontrar errores o tener sugerencias del material se agradece la propuesta de correcciones mediante pull requests. Ligas Notas: https://fundamentos-est.netlify.app/, https://tereom.github.io/fundamentos/ Correos: teresa.ortiz.mancera@gmail.com, alfredo.garbuno@itam.mx. GitHub: https://github.com/tereom/fundamentos Foros de discusion: - Grupo Teresa: slack - Grupo Alfredo: canvas Este trabajo est√° bajo una Licencia Creative Commons Atribuci√≥n 4.0 Internacional. Temario Datos y an√°lisis exploratorio Referencias: (Cleveland 1994), (Chihara and Hesterberg 2018) Visualizaci√≥n y an√°lisis exploratorio Tipos de datos o estudios Muestras dise√±adas y muestras naturales Experimentos y datos observacionales Introducci√≥n a Pruebas de Hip√≥tesis Referencias: (Chihara and Hesterberg 2018) Introducci√≥n a pruebas de hip√≥tesis. Pruebas de permutaciones Muestras pareadas y otros ejemplos Estimaci√≥n y distribuci√≥n de muestreo Referencias: (Chihara and Hesterberg 2018), (Hesterberg 2015) Estimadores y su distribuci√≥n de muestreo Repaso de probabilidad y Teorema del l√≠mite central Introducci√≥n a estimaci√≥n por intervalos Referencias: (Chihara and Hesterberg 2018), (Efron and Tibshirani 1993), (Hesterberg 2015) El m√©todo plugin y el boostrap Bootstrap e Intervalos de confianza. Ejemplos. Estimaci√≥n Referencias: (Chihara and Hesterberg 2018), (Wasserman 2013) Estimaci√≥n por m√°xima verosimilitud Ejemplos de estimaci√≥n por m√°xima verosimilitud y Bootstrap param√©trico Propiedades de estimadores de m√°xima verosimilitud M√°s de pruebas de hip√≥tesis Referencias: (Chihara and Hesterberg 2018), (Wasserman 2013) Pruebas de hip√≥tesis para medias y proporciones: una y dos poblaciones. Introducci√≥n a inferencia bayesiana Referencias: (Kruschke 2015) Introducci√≥n a inferencia bayesiana Ejemplos de distribuciones conjugadas Introducci√≥n a m√©todos computacionales b√°sicos: Muestreadores Metr√≥polis y Gibbs Evaluaci√≥n Tareas semanales 20% Parcial te√≥rico + parcial a casa 40% Final a casa 40% Referencias "],
["principios-de-visualizaci√≥n.html", "Secci√≥n 1 Principios de visualizaci√≥n El cuarteto de Ascombe Introducci√≥n Visualizaci√≥n popular de datos Teor√≠a de visualizaci√≥n de datos Ejemplo: gr√°fica de Minard", " Secci√≥n 1 Principios de visualizaci√≥n El cuarteto de Ascombe En 1971 un estad√≠stico llamado Frank Anscombe (fundador del departamento de Estad√≠stica de la Universidad de Yale) public√≥ cuatro conjuntos de dato. Cada uno consiste de 11 observaciones. La peculariedad de estos conjuntos es que tienen las mismas propiedades estad√≠sticas. Sin embargo, cuando analizamos los datos de manera gr√°fica en un histograma encontramos r√°pidamente que los conjuntos de datos son muy distintos. Media de \\(x\\): 9 Varianza muestral de \\(x\\): 11 Media de \\(y\\): 7.50 Varianza muestral de \\(y\\): 4.12 Correlaci√≥n entre \\(x\\) y \\(y\\): 0.816 L√≠nea de regresi√≥n lineal: \\(y = 3.00 + 0.500x\\) En la gr√°fica del primer conjunto de datos, se ve clara una relaci√≥n lineal simple con un modelo que cumple los supuestos de normalidad. La segunda gr√°fica (arriba a la derecha) muestra unos datos que tienen una asociaci√≥n pero definitivamente no es lineal. En la tercera gr√°fica (abajo a la izquierda) est√°n puntos alineados perfectamente en una l√≠nea recta, excepto por uno de ellos. En la √∫ltima gr√°fica podemos ver un ejemplo en el cual basta tener una observaci√≥n at√≠pica para que se produzca un coeficiente de correlaci√≥n alto a√∫n cuando en realidad no existe una asociaci√≥n lineal entre las dos variables. El cuarteto de Ascombe inspir√≥ una t√©cnica reciente para crear datos que comparten las mismas propiedades estad√≠sticas al igual que en el cuarteto, pero que producen gr√°ficas muy distintas (Matejka, Fitzmaurice). Introducci√≥n La visualizaci√≥n de datos no trata de hacer gr√°ficas ‚Äúbonitas‚Äù o ‚Äúdivertidas‚Äù, ni de simplificar lo complejo o ayudar a una persona ‚Äúque no entiende mucho‚Äù a entender ideas complejas. M√°s bien, trata de aprovechar nuestra gran capacidad de procesamiento visual para exhibir de manera clara aspectos importantes de los datos. El siguiente ejemplo de (Tufte 2006), ilustra claramente la diferencia entre estos dos enfoques. A la izquierda est√°n gr√°ficas (m√°s o menos t√≠picas de Powerpoint) basadas en la filosof√≠a de simplificar, de intentar no ‚Äúahogar‚Äù al lector con datos. El resultado es una colecci√≥n incoherente, de bajo contenido, que no tiene mucho qu√© decir y que es, ‚Äúindeferente al contenido y la evidencia‚Äù. A la derecha est√° una variaci√≥n del redise√±o de Tufte en forma de tabla, que en este caso particular es una manera eficiente de mostrar claramente los patrones que hay en este conjunto simple de datos. ¬øQu√© principios son los que soportan la efectividad de esta tabla sobre la gr√°fica de la derecha? Veremos que hay dos conjuntos de principios importantes: unos relacionados con el dise√±o y otros con la naturaleza del an√°lisis de datos, independientemente del m√©todo de visualizaci√≥n. Visualizaci√≥n popular de datos Publicaciones populares (peri√≥dicos, revistas, sitios internet) muchas veces incluyen visualizaci√≥n de datos como parte de sus art√≠culos o reportajes. En general siguen el mismo patr√≥n que en la visi√≥n tradicionalista de la estad√≠stica: sirven m√°s para divertir que para explicar, tienden a explicar ideas simples y conjuntos chicos de datos, y se consideran como una ‚Äúayuda‚Äù para los ‚Äúlectores menos sofisticados‚Äù. Casi siempre se trata de gr√°ficas triviales (muchas veces con errores graves) que no aportan mucho a art√≠culos que tienen un nivel de complejidad mucho mayor (es la filosof√≠a: lo escrito para el adulto, lo graficado para el ni√±o). Teor√≠a de visualizaci√≥n de datos Existe teor√≠a fundamentada acerca de la visualizaci√≥n. Despu√©s del trabajo pionero de Tukey, los principios e indicadores de Tufte se basan en un estudio de la historia de la graficaci√≥n y ejercicios de muestreo de la pr√°ctica gr√°fica a lo largo de varias disciplinas (¬øcu√°les son las mejores gr√°ficas? ¬øpor qu√©? El trabajo de Cleveland es orientado a la pr√°ctica del an√°lisis de datos (¬øcu√°les gr√°ficas nos han ayudado a mostrar claramente los resultados del an√°lisis?), por una parte, y a algunos estudios de percepci√≥n visual. En resumen, hablaremos de las siguientes gu√≠as: Principios generales del dise√±o anal√≠tico Aplicables a una presentaci√≥n o an√°lisis completos, y como gu√≠a para construir nuevas visualizaciones (Tufte 2006). Principio 1. Muestra comparaciones, contrastes, diferencias. Principio 2. Muestra causalidad, mecanismo, explicaci√≥n, estructura sistem√°tica. Principio 3. Muestra datos multivariados, es decir, m√°s de una o dos variables. Principio 4. Integra palabras, n√∫meros, im√°genes y diagramas. Principio 5. Describe la totalidad de la evidencia. Muestra fuentes usadas y problemas relevantes. Principio 6. Las presentaciones anal√≠ticas, a fin de cuentas, se sostienen o caen dependiendo de la calidad, relevancia e integridad de su contenido. T√©cnicas de visualizaci√≥n Esta categor√≠a incluye t√©cnicas espec√≠ficas que dependen de la forma de nuestros datos y el tipo de pregunta que queremos investigar (Tukey (1977), Cleveland (1993), Cleveland (1994), Tufte (2006)). Tipos de gr√°ficas: cuantiles, histogramas, caja y brazos, gr√°ficas de dispersi√≥n, puntos/barras/ l√≠neas, series de tiempo. T√©cnicas para mejorar gr√°ficas: Transformaci√≥n de datos, transparencia, vibraci√≥n, banking 45, suavizamiento y bandas de confianza. Peque√±os m√∫ltiplos Indicadores de calidad gr√°fica Aplicables a cualquier gr√°fica en particular. Estas son gu√≠as concretas y relativamente objetivas para evaluar la calidad de una gr√°fica (Tufte 1986). Integridad Gr√°fica. El factor de enga√±o, es decir, la distorsi√≥n gr√°fica de las cantidades representadas, debe ser m√≠nimo. Chartjunk. Minimizar el uso de decoraci√≥n gr√°fica que interfiera con la interpretaci√≥n de los datos: 3D, rejillas, rellenos con patrones. Tinta de datos. Maximizar la proporci√≥n de tinta de datos vs. tinta total de la gr√°fica. For non-data- ink, less is more. For data-ink, less is a bore. Densidad de datos. Las mejores gr√°ficas tienen mayor densidad de datos, que es la raz√≥n entre el tama√±o del conjunto de datos y el √°rea de la gr√°fica. Las gr√°ficas se pueden encoger mucho. Percepci√≥n visual. Algunas tareas son m√°s f√°ciles para el ojo humano que otras (Cleveland 1994). Factor de enga√±o y Chartjunk El factor de enga√±o es el cociente entre el efecto mostrado en una gr√°fica y el efecto correspondiente en los datos. Idealmente, el factor de enga√±o debe ser 1 (ninguna distorsi√≥n). El chartjunk son aquellos elementos gr√°ficos que no corresponden a variaci√≥n de datos, o que entorpecen la interpretaci√≥n de una gr√°fica. Estos son los indicadores de calidad m√°s f√°ciles de entender y aplicar, y afortunadamente cada vez son menos comunes. Un dise√±o popular que califica como chartjunk y adem√°s introduce factores de enga√±o es el pie de 3D. En la gr√°fica de la derecha, podemos ver como la rebanada C se ve m√°s grande que la rebanada A, aunque claramente ese no es el caso (factor de enga√±o). La raz√≥n es la variaci√≥n en la perspectiva que no corresponde a variaci√≥n en los datos (chartjunk). Cr√≠tica gr√°fica: Gr√°fica de pie Todav√≠a elementos que pueden mejorar la comprensi√≥n de nuestra gr√°fica de pie: se trata de la decodificiaci√≥n que hay que hacer categor√≠a - color - cuantificaci√≥n. Podemos agregar las etiquetas como se muestra en la serie de la derecha, pero entonces: ¬øpor qu√© no mostrar simplemente la tabla de datos? ¬øqu√© agrega el pie a la interpretaci√≥n? La deficiencias en el pie se pueden ver claramente al intentar graficar m√°s categor√≠as (13) . En el primer pie no podemos distinguir realmente cu√°les son las categor√≠as grandes y cu√°les las chicas, y es muy dif√≠cil tener una imagen mental clara de estos datos. Agregar los porcentajes ayuda, pero entonces, otra vez, preguntamos cu√°l es el prop√≥sito del pie. La tabla de la izquierda hace todo el trabajo (una vez que ordenamos las categr√≠as de la m√°s grande a la m√°s chica). Es posible hacer una gr√°fica de barras como la de abajo a la izquierda. Hay otros tipos de chartjunk comunes: uno es la textura de barras, por ejemplo. El efecto es la producci√≥n de un efecto moir√© que es desagradable y quita la atenci√≥n de los datos, como en la gr√°fica de barras de abajo. Otro com√∫n son las rejillas, como mostramos en las gr√°ficas de la izquierda. N√≥tese como en estos casos hay efectos √≥pticos no planeados que degradan la percepci√≥n de los patrones en los datos. Peque√±os m√∫ltiplos y densidad gr√°fica La densidad de una gr√°fica es el tama√±o del conjunto de datos que se grafica comparado con el √°rea total de la gr√°fica. En el siguiente ejemplo, graficamos en logaritmo-10 de cabezas de ganado en Francia (cerdos, res, ovejas y caballos). La gr√°fica de la izquierda es pobre en densidad pues s√≥lo representa 4 datos. La manera m√°s f√°cil de mejorar la densidad es hacer m√°s chica la gr√°fica: La raz√≥n de este encogimiento es una que tiene qu√© ver con las oportunidades perdidas de una gr√°fica grande. Si repetimos este mismo patr√≥n (misma escala, mismos tipos de ganado) para distintos pa√≠ses obtenemos la siguiente gr√°fica: Esta es una gr√°fica de puntos. Es √∫til como sustituto de una gr√°fica de barras, y es superior en el sentido de que una mayor proporci√≥n de la tinta que se usa es tinta de datos. Otra vez, mayor proporci√≥n de tinta de datos representa m√°s oportunidades que se pueden capitalizar, como muestra la gr√°fica de punto y l√≠neas que mostramos al principio (rendimiento en campos de cebada). M√°s peque√±os m√∫ltiplos Los peque√±os m√∫ltiplos presentan oportunidades para mostrar m√°s acerca de nuestro problema de inter√©s. Consideramos por ejemplo la relaci√≥n de radiaci√≥n solar y niveles de ozono: ggplot(airquality, aes(x=Solar.R, y=Ozone)) + geom_point() + geom_smooth(method = &quot;loess&quot;, span = 1) En el ejemplo anterior incluyendo una variable adicional (velocidad del viento) podemos entender m√°s acerca de la relaci√≥n de radiaci√≥n solar y niveles de ozono: airquality$Wind_cat &lt;- cut(airquality$Wind, breaks = quantile(airquality$Wind, c(0, 1/3, 2/3, 1)), include.lowest = TRUE) ggplot(airquality, aes(x=Solar.R, y=Ozone)) + geom_point() + facet_wrap(~Wind_cat) + geom_smooth(method = &quot;loess&quot;, span = 0.8, se = FALSE, method.args = list(degree = 1, family=&quot;symmetric&quot;)) Tinta de datos Maximizar la proporci√≥n de tinta de datos en nuestras gr√°ficas tiene beneficios inmediatos. La regla es: si hay tinta que no representa variaci√≥n en los datos, o la eliminaci√≥n de esa tinta no representa p√©rdidas de significado, esa tinta debe ser eliminada. El ejemplo m√°s claro es el de las rejillas en gr√°ficas y tablas: ¬øPor qu√© usar grises en lugar de negros? La respuesta tiene qu√© ver con el principio de tinta de datos: si marcamos las diferencias sutil pero claramente, tenemos m√°s oportunidades abiertas para hacer √©nfasis en lo que nos interesa: a una gr√°fica o tabla saturada no se le puede hacer m√°s - es dif√≠cil agregar elementos adicionales que ayuden a la comprensi√≥n. Si comenzamos marcando con sutileza, entonces se puede hacer m√°s. Los mapas geogr√°ficos son un buen ejemplo de este principio. El espacio en blanco es suficientemente bueno para indicar las fronteras en una tabla, y facilita la lectura: Para un ejemplo del proceso de redise√±o de una tabla, ver aqu√≠. Finalmente, podemos ver un ejemplo que intenta incorporar los elementos del dise√±o anal√≠tico, incluyendo peque√±os m√∫ltiplos: Decoraci√≥n Percepci√≥n de escala Entre la percepci√≥n visual y la interpretaci√≥n de una gr√°fica est√°n impl√≠citas tareas visuales espec√≠ficas que las personas debemos realizar para ver correctamente la gr√°fica. En la d√©cada de los ochenta, William S. Cleveland y Robert McGill realizaron algunos experimentos identificando y clasificando estas tareas para diferentes tipos de gr√°ficos (Cleveland and McGill 1984). En estos, se le pregunta a la persona que compare dos valores dentro de una gr√°fica, por ejemplo, en dos barras en una gr√°fica de barras, o dos rebanadas de una gr√°fica de pie. Los resultados de Cleveland y McGill fueron replicados por Heer y Bostock en 2010 y los resultados se muestran en las gr√°ficas de la derecha: Ejemplo: gr√°fica de Minard Concluimos esta secci√≥n con una gr√°fica que, aunque poco com√∫n, ejemplifica los principios de una buena gr√°fica, y es reconocida como una de las mejores visualizaciones de la historia. Una gr√°fica excelente, presenta datos interesantes de forma bien dise√±ada: es una cuesti√≥n de fondo, de dise√±o, y estad√≠stica‚Ä¶ [Se] compone de ideas complejas comunicadas con claridad, precisi√≥n y eficiencia. ‚Ä¶ [Es] lo que da al espectador la mayor cantidad de ideas, en el menor tiempo, con la menor cantidad de tinta, y en el espacio m√°s peque√±o. ‚Ä¶ Es casi siempre multivariado. ‚Ä¶ Una excelente gr√°fica debe decir la verdad acerca de los datos. (Tufte, 1983) La famosa visualizaci√≥n de Charles Joseph Minard de la marcha de Napole√≥n sobre Mosc√∫, ilustra los principios de una buena gr√°fica. Tufte se√±ala que esta imagen ‚Äúbien podr√≠a ser el mejor gr√°fico estad√≠stico jam√°s dibujado‚Äù, y sostiene que ‚Äúcuenta una historia rica y coherente con sus datos multivariados, mucho m√°s esclarecedora que un solo n√∫mero que rebota en el tiempo‚Äù. Se representan seis variables: el tama√±o del ej√©rcito, su ubicaci√≥n en una superficie bidimensional, la direcci√≥n del movimiento del ej√©rcito y la temperatura en varias fechas durante la retirada de Mosc√∫\". Hoy en d√≠a Minard es reconocido como uno de los principales contribuyentes a la teor√≠a de an√°lisis de datos y creaci√≥n de infograf√≠as con un fundamento estad√≠stico. Se grafican 6 variables: el n√∫mero de tropas de Napole√≥n, la distancia, la temperatura, la latitud y la longitud, la direcci√≥n en que viajaban las tropas y la localizaci√≥n relativa a fechas espec√≠ficas. La gr√°fica de Minard, como la describe E.J. Marey, parece ‚Äúdesafiar la pluma del historiador con su brutal elocuencia‚Äù, la combinaci√≥n de datos del mapa, y la serie de tiempo, dibujados en 1869, ‚Äúretratan una secuencia de p√©rdidas devastadoras que sufrieron las tropas de Napole√≥n en 1812‚Äù. Comienza en la izquierda, en la frontera de Polonia y Rusia, cerca del r√≠o Niemen. La l√≠nea gruesa dorada muestra el tama√±o de la Gran Armada (422,000) en el momento en que invad√≠a Rusia en junio de 1812. El ancho de esta banda indica el tama√±o de la armada en cada punto del mapa. En septiembre, la armada lleg√≥ a Mosc√∫, que ya hab√≠a sido saqueada y dejada des√©rtica, con s√≥lo 100,000 hombres. El camino del retiro de Napole√≥n desde Mosc√∫ est√° representado por la l√≠nea oscura (gris) que est√° en la parte inferior, que est√° relacionada a su vez con la temperatura y las fechas en el diagrama de abajo. Fue un invierno muy fr√≠o, y muchos se congelaron en su salida de Rusia. Como se muestra en el mapa, cruzar el r√≠o Berezina fue un desastre, y el ej√©rcito de Napole√≥n logr√≥ regresar a Polonia con tan s√≥lo 10,000 hombres. Tambi√©n se muestran los movimientos de las tropas auxiliaries, que buscaban proteger por atr√°s y por la delantera mientras la armada avanzaba hacia Mosc√∫. La gr√°fica de Minard cuenta una historia rica y cohesiva, coherente con datos multivariados y con los hechos hist√≥ricos, y que puede ser m√°s ilustrativa que tan s√≥lo representar un n√∫mero rebotando a lo largo del tiempo. Referencias "],
["an√°lisis-exploratorio.html", "Secci√≥n 2 An√°lisis exploratorio El papel de la exploraci√≥n en el an√°lisis de datos Algunos conceptos b√°sicos Ejemplos Loess", " Secci√≥n 2 An√°lisis exploratorio ‚ÄúExploratory data analysis can never be the whole story, but nothing else can serve as the foundation stone ‚Äìas the first step.‚Äù ‚Äî John Tukey ‚ÄúThe simple graph has brought more information to the data analyst‚Äôs mind than any other device.‚Äù ‚Äî John Tukey El papel de la exploraci√≥n en el an√°lisis de datos El est√°ndar cient√≠fico para contestar preguntas o tomar decisiones es uno que se basa en el an√°lisis de datos. Es decir, en primer lugar se deben reunir todos los datos disponibles que puedan contener o sugerir alguna gu√≠a para entender mejor la pregunta o la decisi√≥n a la que nos enfrentamos. Esta recopilaci√≥n de datos ‚Äîque pueden ser cualitativos, cuantitativos, o una mezcla de los dos‚Äî debe entonces ser analizada para extraer informaci√≥n relevante para nuestro problema. En an√°lisis de datos existen dos distintos tipos de trabajo: El trabajo exploratorio o de detective: ¬øcu√°les son los aspectos importantes de estos datos? ¬øqu√© indicaciones generales muestran los datos? ¬øqu√© tareas de an√°lisis debemos empezar haciendo? ¬øcu√°les son los caminos generales para formular con precisi√≥n y contestar algunas preguntas que nos interesen? El trabajo inferencial, confirmatorio, o de juez: ¬øc√≥mo evaluar el peso de la evidencia de los descubrimientos del paso anterior? ¬øqu√© tan bien soportadas est√°n las respuestas y conclusiones por nuestro conjunto de datos? Algunos conceptos b√°sicos Empezamos explicando algunas ideas que no ser√°n √∫tiles m√°s adelante. Por ejemplo, los siguientes datos fueron registrados en un restaurante durante cuatro d√≠as consecutivos: library(tidyverse) library(patchwork) source(&quot;R/funciones_auxiliares.R&quot;) # usamos los datos tips del paquete reshape2 tips &lt;- reshape2::tips # renombramos variables y niveles propinas &lt;- tips %&gt;% rename(cuenta_total = total_bill, propina = tip, sexo = sex, fumador = smoker, dia = day, momento = time, num_personas = size) %&gt;% mutate(sexo = recode(sexo, Female = &quot;Mujer&quot;, Male = &quot;Hombre&quot;), fumador = recode(fumador, No = &quot;No&quot;, Yes = &quot;Si&quot;), dia = recode(dia, Sun = &quot;Dom&quot;, Sat = &quot;Sab&quot;, Thur = &quot;Jue&quot;, Fri = &quot;Vie&quot;), momento = recode(momento, Dinner = &quot;Cena&quot;, Lunch = &quot;Comida&quot;)) %&gt;% select(-sexo) %&gt;% mutate(dia = fct_relevel(dia, c(&quot;Jue&quot;, &quot;Vie&quot;, &quot;Sab&quot;, &quot;Dom&quot;))) Y vemos una muestra sample_n(propinas, 10) %&gt;% formatear_tabla() ## Warning in kableExtra::kable_styling(., latex_options = c(&quot;striped&quot;), ## bootstrap_options = c(&quot;striped&quot;, : Please specify format in kable. kableExtra ## can customize either HTML or LaTeX outputs. See https://haozhu233.github.io/ ## kableExtra/ for details. cuenta_total propina fumador dia momento num_personas 15.69 1.50 Si Dom Cena 2 16.99 1.01 No Dom Cena 2 14.15 2.00 No Jue Comida 2 24.52 3.48 No Dom Cena 3 20.92 4.08 No Sab Cena 2 12.48 2.52 No Jue Comida 2 35.26 5.00 No Dom Cena 4 23.95 2.55 No Dom Cena 2 10.27 1.71 No Dom Cena 2 11.24 1.76 Si Sab Cena 2 Aqu√≠ la unidad de observaci√≥n es una cuenta particular. Tenemos tres mediciones num√©ricas de cada cuenta: c√∫anto fue la cuenta total, la propina, y el n√∫mero de personas asociadas a la cuenta. Los datos est√°n separados seg√∫n se fum√≥ o no en la mesa, y temporalmente en dos partes: el d√≠a (Jueves, Viernes, S√°bado o Domingo), cada uno separado por Cena y Comida. Denotamos por \\(x\\) el valor de medici√≥n de una unidad de observaci√≥n. Usualmente utilizamos sub-√≠ndices para identificar entre diferentes puntos de datos (observaciones), por ejemplo, \\(x_n\\) para la \\(n-\\)√©sima observaci√≥n. De tal forma que una colecci√≥n de \\(N\\) observaciones la escribimos como \\[\\begin{align} \\{x_1, \\ldots, x_N\\}. \\end{align}\\] El primer tipo de comparaciones que nos interesa hacer es para una medici√≥n: ¬øVar√≠an mucho o poco los datos de un tipo de medici√≥n? ¬øCu√°les son valores t√≠picos o centrales? ¬øExisten valores at√≠picos? Supongamos entonces que consideramos simplemente la variable de cuenta_total. Podemos comenzar por ordenar los datos, y ver cu√°les datos est√°n en los extremos y cu√°les est√°n en los lugares centrales: En general la colecci√≥n de datos no est√° ordenada por sus valores. Esto es debido a que las observaciones en general se recopilan de manera aleatoria. Utilizamos la notaci√≥n de \\(\\sigma(n)\\) para denotar un reordenamiento de los datos de tal forma \\[\\begin{align} \\{x_{\\sigma(1)}, \\ldots, x_{\\sigma(N)}\\}, \\end{align}\\] y que satisface la siguiente serie de desigualdades \\[\\begin{align} x_{\\sigma(1)} \\leq \\ldots \\leq x_{\\sigma(N)}. \\end{align}\\] propinas &lt;- propinas %&gt;% mutate(orden_cuenta = rank(cuenta_total, ties.method = &quot;first&quot;), f = (orden_cuenta - 0.5) / n()) cuenta &lt;- propinas %&gt;% select(orden_cuenta, f, cuenta_total) %&gt;% arrange(f) bind_rows(head(cuenta), tail(cuenta)) %&gt;% formatear_tabla() orden_cuenta f cuenta_total 1 0.0020492 3.07 2 0.0061475 5.75 3 0.0102459 7.25 4 0.0143443 7.25 5 0.0184426 7.51 6 0.0225410 7.56 239 0.9774590 44.30 240 0.9815574 45.35 241 0.9856557 48.17 242 0.9897541 48.27 243 0.9938525 48.33 244 0.9979508 50.81 Tambi√©n podemos graficar los datos en orden, interpolando valores consecutivos. g_orden &lt;- ggplot(cuenta, aes(y = orden_cuenta, x = cuenta_total)) + geom_point(colour = &quot;red&quot;, alpha = 0.5) + labs(subtitle = &quot;Cuenta total&quot;) g_cuantiles &lt;- ggplot(cuenta, aes(y = f, x = cuenta_total)) + geom_point(colour = &quot;red&quot;, alpha = 0.5) + geom_line(alpha = 0.5) + labs(subtitle = &quot;&quot;) g_orden + g_cuantiles A esta funci√≥n le llamamos la funci√≥n de cuantiles para la variable cuenta_total. Nos sirve para comparar directamente los distintos valores que observamos los datos seg√∫n el orden que ocupan. La funci√≥n de cuantiles muestral esta definida por \\[\\begin{align} \\hat{F}(x) = \\frac1N \\sum_{n = 1}^N \\mathbb{1}\\{x_n \\leq x\\}, \\end{align}\\] donde la funcion indicadora est√° definida por \\[\\begin{align} 1\\{ x \\leq t\\} = \\begin{cases} 1, \\text{ si } x \\leq t \\\\ 0, \\text{ en otro caso} \\end{cases}. \\end{align}\\] Observaci√≥n: la funci√≥n de cuantiles definida arriba tambi√©n es conocida como la funci√≥n de acumulaci√≥n emp√≠rica. Se puede encontrar la siguiente notaci√≥n en la literatura \\[\\begin{align} \\hat F(x) = F_N(x) = \\text{Pr}_N(X \\leq x), \\end{align}\\] as√≠ como \\[\\begin{align} \\text{Pr}_N(X \\geq x) = 1 - \\hat F(x). \\end{align}\\] Para una medici√≥n de inter√©s \\(x\\) con posibles valores en el intervalo \\([a, b]\\). Comprueba que \\(\\hat F(a) = 0\\) y \\(\\hat F(b) = 1\\) para cualquier colecci√≥n de datos de tama√±o \\(N.\\) La gr√°fica anterior, tambi√©n nos sirve para poder estudiar la dispersi√≥n y valores centrales de los datos observados. Por ejemplo, podemos notar que: El rango de datos va de unos 3 d√≥lares hasta 50 d√≥lares Los valores centrales ‚Äîdel cuantil 0.25 al 0.75, por decir un ejemplo‚Äî est√°n entre unos 13 y 25 d√≥lares El cuantil 0.5 (o tambi√©n conocido como mediana) est√° alrededor de 18 d√≥lares. ¬øC√≥mo definir√≠as la mediana en t√©rminos de la funci√≥n de cuantiles? Pista: Considera los casos por separado para \\(N\\) impar o par. √âste √∫ltimo puede ser utilizado para dar un valor central de la distribuci√≥n de valores para cuenta_total. Asimismo podemos dar res√∫menes m√°s refinados si es necesario. Por ejemplo, podemos reportar que: El cuantil 0.95 es de unos 35 d√≥lares ‚Äî s√≥lo 5% de las cuentas son de m√°s de 35 d√≥lares El cuantil 0.05 es de unos 8 d√≥lares ‚Äî s√≥lo 5% de las cuentas son de 8 d√≥lares o menos. Finalmente, la forma de la gr√°fica se interpreta usando su pendiente (tasa de cambio) haciendo comparaciones en diferentes partes de la gr√°fica: La distribuci√≥n de valores tiene asimetr√≠a: el 10% de las cuentas m√°s altas tiene considerablemente m√°s dispersi√≥n que el 10% de las cuentas m√°s bajas. Entre los cuantiles 0.2 y 0.5 es donde existe mayor densidad de datos: la pendiente (tasa de cambio) es alta, lo que significa que al avanzar en los valores observados, los cuantiles (el porcentaje de casos) aumenta r√°pidamente. Cuando la pendiente es casi plana, quiere decir que los datos tienen m√°s dispersi√≥n local o est√°n m√°s separados. En algunos casos, es m√°s natural hacer un histograma, donde dividimos el rango de la variable en cubetas o intervalos (en este caso de igual longitud), y graficamos por medio de barras cu√°ntos datos caen en cada cubeta: Es una gr√°fica m√°s popular, pero perdemos cierto nivel de detalle, y distintas particiones resaltan distintos aspectos de los datos. ¬øC√≥mo se ve la gr√°fica de cuantiles de las propinas? ¬øC√≥mo crees que esta gr√°fica se compara con distintos histogramas? g_1 &lt;- ggplot(propinas, aes(sample = propina)) + geom_qq(distribution = stats::qunif) + xlab(&quot;f&quot;) + ylab(&quot;propina&quot;) g_1 Observaci√≥n. Cuando hay datos repetidos, los cuantiles tienen que interpretarse como sigue: el cuantil-\\(f\\) con valor \\(q\\) satisface que existe una proporci√≥n aproximada \\(f\\) de los datos que est√°n en el valor \\(q\\) o por debajo de √©ste, pero no necesariamente exactamente una proporci√≥n \\(f\\) de los datos estan en \\(q\\) o por debajo. Observaci√≥n. La definici√≥n de cuantiles muestrales no es √∫nica y distintos programas utilizan diferentes acercamientos (incluso puede variar entre paquetes o funciones de un mismo programa), ver Hyndman y Fan 2012. Finalmente, una gr√°fica m√°s compacta que resume la gr√°fica de cuantiles o el histograma es el diagrama de caja y brazos. Mostramos dos versiones, la cl√°sica de Tukey (T) y otra versi√≥n menos com√∫n de Spear/Tufte (ST): library(ggthemes) cuartiles &lt;- quantile(cuenta$cuenta_total) t(cuartiles) %&gt;% formatear_tabla() 0% 25% 50% 75% 100% 3.07 13.3475 17.795 24.1275 50.81 g_1 &lt;- ggplot(cuenta, aes(x = f, y = cuenta_total)) + labs(subtitle = &quot;Gr√°fica de cuantiles: Cuenta total&quot;) + geom_hline(yintercept = cuartiles[2], colour = &quot;gray&quot;) + geom_hline(yintercept = cuartiles[3], colour = &quot;gray&quot;) + geom_hline(yintercept = cuartiles[4], colour = &quot;gray&quot;) + geom_point(alpha = 0.5) + geom_line() g_2 &lt;- ggplot(cuenta, aes(x = factor(&quot;ST&quot;, levels =c(&quot;ST&quot;)), y = cuenta_total)) + geom_tufteboxplot() + labs(subtitle = &quot; &quot;) + xlab(&quot;&quot;) + ylab(&quot;&quot;) g_3 &lt;- ggplot(cuenta, aes(x = factor(&quot;T&quot;), y = cuenta_total)) + geom_boxplot() + labs(subtitle = &quot; &quot;) + xlab(&quot;&quot;) + ylab(&quot;&quot;) g_4 &lt;- ggplot(cuenta, aes(x = factor(&quot;P&quot;), y = cuenta_total)) + geom_jitter(height = 0, width =0.2, alpha = 0.5) + labs(subtitle = &quot; &quot;) + xlab(&quot;&quot;) + ylab(&quot;&quot;) g_5 &lt;- ggplot(cuenta, aes(x = factor(&quot;V&quot;), y = cuenta_total)) + geom_violin() + labs(subtitle = &quot; &quot;) + xlab(&quot;&quot;) + ylab(&quot;&quot;) g_1 + g_2 + g_3 + g_4 + plot_layout(widths = c(8, 2, 2, 2)) El diagrama de la derecha explica los elementos de la versi√≥n t√≠pica del diagrama de caja y brazos (boxplot). RIC se refiere al *Rango Intercuant√≠lico**, definido por la diferencia entre los cuantiles 25% y 75%. Figura: Jumanbar / CC BY-SA Hasta ahora hemos utilizado la definici√≥n general de cuantiles. Donde consideramos el cuantil \\(q\\), para buscar \\(x\\) tal que \\(\\hat F(x) = q.\\) Hay valores t√≠picos de inter√©s que corresponden a \\(q\\) igual a 25%, 50% y 75%. √âstos valores se denominan cuartiles. Ventajas en el an√°lisis inicial En un principio del an√°lisis, estos res√∫menes (cuantiles) pueden ser m√°s √∫tiles que utilizar medias y varianzas, por ejemplo. La raz√≥n es que los cuantiles: Son cantidades m√°s f√°cilmente interpretables Los cuantiles centrales son m√°s resistentes a valores at√≠picos que medias o varianzas Sin embargo, permite identificar valores extremos Es f√°cil comparar cuantiles de distintos bonches de datos Media y desviaci√≥n est√°ndar Las medidas m√°s comunes de localizaci√≥n y dispersi√≥n para un conjunto de datos son la media muestral y la desviaci√≥n est√°ndar muestral. En general, no son muy apropiadas para iniciar el an√°lisis exploratorio, pues: Son medidas m√°s dif√≠ciles de interpretar y explicar que los cuantiles. En este sentido, son medidas especializadas. Por ejemplo, intenta explicar intuitivamente qu√© es la media. No son resistentes a valores at√≠picos o err√≥neos. Su falta de resistencia los vuelve poco √∫tiles en las primeras etapas de limpieza y descripci√≥n. La media, o promedio, se denota por \\(\\bar x\\) y se define como \\[\\begin{align} \\bar x = \\frac1N \\sum_{n = 1}^N x_n. \\end{align}\\] La desviaci√≥n est√°ndar muestral se define como \\[\\begin{align} \\text{std}(x) = \\sqrt{\\frac1{N-1} \\sum_{n = 1}^N (x_n - \\bar x)^2}. \\end{align}\\] Sin embargo, La media y desviaci√≥n est√°ndar son computacionalmente convenientes. Para el trabajo de modelado estas medidas de resumen tienen ventajas claras (bajo ciertos supuestos te√≥ricos). En muchas ocasiones conviene usar estas medidas pues permite hacer comparaciones hist√≥ricas o tradicionales ‚Äîpues an√°lisis anteriores pudieran estar basados en √©stas. Medias recortadas. Una medida intermedia entre la mediana y la media es la media recortada. Si denotamos \\(G\\) al conjunto de datos original, y \\(p\\) un valor entre \\(0\\) y \\(1\\), entonces \\(G_p\\) es el coonjunto de datos que resulta de \\(G\\) cuando se excluye de \\(G\\) la proporci√≥n \\(p\\) de los datos m√°s bajos y la proporci√≥n \\(p\\) de datos m√°s altos. La media recortada-\\(p\\) es el promedio de los valores en \\(G_p\\). Considera el caso de tener \\(N\\) observaciones y asume que ya tienes calculado el promedio para dichas observaciones. Este promedio lo denotaremos por \\(\\bar x_N\\). Ahora, considera que has obtenido \\(M\\) observaciones m√°s. Escribe una f√≥rmula recursiva para la media del conjunto total de datos \\(\\bar x_{N+M}\\) en funci√≥n de lo que ya ten√≠as precalculado \\(\\bar x_N.\\) ¬øEn qu√© situaciones esta propiedad puede ser conveniente? Ejemplos Precios de casas En este ejemplo consideremos los datos de precios de ventas de la ciudad de Ames, Iowa. En particular nos interesa entender la variaci√≥n del precio de las casas. Por este motivo calculamos los cuantiles que corresponden al 25%, 50% y 75% (cuartiles), as√≠ como el m√≠nimo y m√°ximo de los precios de las casas: quantile(casas %&gt;% pull(precio_miles)) ## 0% 25% 50% 75% 100% ## 37.9 132.0 165.0 215.0 755.0 Comprueba que el m√≠nimo y m√°ximo est√°n asociados a los cuantiles 0% y 100%, respectivamente. Una posible comparaci√≥n es considerar los precios y sus variaci√≥n en funci√≥n de zona de la ciudad en que se encuentra una vivienda. Podemos usar diagramas de caja y brazos para hacer una comparaci√≥n burda de los precios en distintas zonas de la ciudad: ggplot(casas, aes(x = nombre_zona, y = precio_miles)) + geom_boxplot() + coord_flip() La primera pregunta que nos hacemos es c√≥mo pueden variar las caracter√≠sticas de las casas dentro de cada zona. Para esto, podemos considerar el √°rea de las casas. En lugar de graficar el precio, graficamos el precio por metro cuadrado, por ejemplo: ggplot(casas, aes(x = nombre_zona, y = precio_m2)) + geom_boxplot() + coord_flip() Podemos cuantificar la variaci√≥n que observamos de zona a zona y la variaci√≥n que hay dentro de cada una de las zonas. Una primera aproximaci√≥n es observar las variaci√≥n del precio al calcular la mediana dentro de cada zona, y despu√©s cuantificar por medio de cuantiles c√≥mo var√≠a la mediana entre zonas: casas %&gt;% group_by(nombre_zona) %&gt;% summarise(mediana_zona = median(precio_m2), .groups = &quot;drop&quot;) %&gt;% pull(mediana_zona) %&gt;% quantile() %&gt;% round() ## 0% 25% 50% 75% 100% ## 963 1219 1298 1420 1725 Por otro lado, las variaciones con respecto a las medianas dentro de cada zona, por grupo, se resume como: quantile(casas %&gt;% group_by(nombre_zona) %&gt;% mutate(residual = precio_m2 - median(precio_m2)) %&gt;% pull(residual)) %&gt;% round() ## 0% 25% 50% 75% 100% ## -765 -166 0 172 1314 N√≥tese que este √∫ltimo paso tiene sentido pues la variaci√≥n dentro de las zonas, en t√©rminos de precio por metro cuadrado, es similar. Esto no lo podr√≠amos haber hecho de manera efectiva si se hubiera utilizado el precio de las casas sin ajustar por su tama√±o. Podemos resumir este primer an√°lisis de varianza con un par de gr√°ficas de cuantiles (Cleveland 1993): mediana &lt;- median(casas$precio_m2) resumen &lt;- casas %&gt;% group_by(nombre_zona) %&gt;% mutate(mediana_zona = median(precio_m2)) %&gt;% mutate(residual = precio_m2 - mediana_zona) %&gt;% ungroup() %&gt;% mutate(mediana_zona = mediana_zona - mediana) %&gt;% select(nombre_zona, mediana_zona, residual) %&gt;% pivot_longer(mediana_zona:residual, names_to = &quot;tipo&quot;, values_to = &quot;valor&quot;) ggplot(resumen, aes(sample = valor)) + geom_qq(distribution = stats::qunif) + facet_wrap(~ tipo) + ylab(&quot;Precio por m2&quot;) + xlab(&quot;f&quot;) + labs(subtitle = &quot;Precio por m2 por zona&quot;, caption = paste0(&quot;Mediana total de &quot;, round(mediana))) Vemos que la mayor parte de la variaci√≥n del precio por metro cuadrado ocurre dentro de cada zona, una vez que controlamos por el tama√±o de las casas. La variaci√≥n dentro de cada zona es aproximadamente sim√©trica, aunque la cola derecha es ligeramente m√°s larga con algunos valores extremos. Podemos seguir con otro indicador importante: la calificaci√≥n de calidad de los terminados de las casas. Como primer intento podr√≠amos hacer: Lo que indica que las calificaciones de calidad est√°n distribuidas de manera muy distinta a lo largo de las zonas, y que probablemente no va ser simple desentra√±ar qu√© variaci√≥n del precio se debe a la zona y cu√°l se debe a la calidad. Prueba Enlace Consideremos la prueba Enlace (2011) de matem√°ticas para primarias. Una primera pregunta que alguien podr√≠a hacerse es: ¬øcu√°les escuelas son mejores en este rubro, las privadas o las p√∫blicas? enlace_tbl &lt;- enlace %&gt;% group_by(tipo) %&gt;% summarise(n_escuelas = n(), cuantiles = list(cuantil(mate_6, c(0.05, 0.25, 0.5, 0.75, 0.95)))) %&gt;% unnest(cols = cuantiles) %&gt;% mutate(valor = round(valor)) enlace_tbl %&gt;% spread(cuantil, valor) %&gt;% formatear_tabla() tipo n_escuelas 0.05 0.25 0.5 0.75 0.95 Ind√≠gena/Conafe 13599 304 358 412 478 588 General 60166 380 454 502 548 631 Particular 6816 479 551 593 634 703 Para un an√°lisis exploratorio podemos utilizar distintas gr√°ficas. Por ejemplo, podemos utilizar nuevamente las gr√°ficas de caja y brazos, as√≠ como graficar los percentiles. N√≥tese que en la gr√°fica 1 se utilizan los cuantiles 0.05, 0.25, 0.5, 0.75 y 0.95: Se puede discutir qu√© tan apropiada es cada gr√°fica con el objetivo de realizar comparaciones. Sin duda, graficar m√°s cuantiles es m√°s √∫til para hacer comparaciones. Por ejemplo, en la Gr√°fica 1 podemos ver que la mediana de las escuelas generales est√° cercana al cuantil 5% de las escuelas particulares. Por otro lado, el diagrama de caja y brazos muestra tambi√©n valores ‚Äúat√≠picos‚Äù. Es importante notar que una comparaci√≥n m√°s robusta se puede lograr por medio de pruebas de hip√≥tesis, las cuales veremos mas adelante en el curso. Regresando a nuestro an√°lisis exploratorio, notemos que la diferencia es considerable entre tipos de escuela. Antes de contestar prematuramente la pregunta: ¬øcu√°les son las mejores escuelas? busquemos mejorar la interpretabilidad de nuestras comparaciones usando los principios 2 y 3. Podemos comenzar por agregar, por ejemplo, el nivel del marginaci√≥n del municipio donde se encuentra la escuela. Para este objetivo, podemos usar p√°neles (peque√±os m√∫ltiplos √∫tiles para hacer comparaciones) y graficar: Esta gr√°fica pone en contexto la pregunta inicial, y permite evidenciar la dificultad de contestarla. En particular: Se√±ala que la pregunta no s√≥lo debe concentarse en el tipo de ‚Äúsistema‚Äù: p√∫blica, privada, etc. Por ejemplo, las escuelas p√∫blicas en zonas de marginaci√≥n baja no tienen una distribuci√≥n de calificaciones muy distinta a las privadas en zonas de marginaci√≥n alta. El contexto de la escuela es importante. Debemos de pensar qu√© factores ‚Äìpor ejemplo, el entorno familiar de los estudiantes‚Äì puede resultar en comparaciones que favorecen a las escuelas privadas. Un ejemplo de esto es considerar si los estudiantes tienen que trabajar o no. A su vez, esto puede o no ser reflejo de la calidad del sistema educativo. Si esto es cierto, entonces la pregunta inicial es demasiado vaga y mal planteada. Quiz√° deber√≠amos intentar entender cu√°nto ‚Äúaporta‚Äù cada escuela a cada estudiante, como medida de qu√© tan buena es cada escuela. Estados y calificaciones en SAT ¬øC√≥mo se relaciona el gasto por alumno, a nivel estatal, con sus resultados acad√©micos? Hay trabajo considerable en definir estos t√©rminos, pero supongamos que tenemos el siguiente conjunto de datos (Guber 1999), que son datos oficiales agregados por estado de Estados Unidos. Consideremos el subconjunto de variables sat, que es la calificaci√≥n promedio de los alumnos en cada estado (para 1997) y expend, que es el gasto en miles de d√≥lares por estudiante en (1994-1995). sat &lt;- read_csv(&quot;data/sat.csv&quot;) sat_tbl &lt;- sat %&gt;% select(state, expend, sat) %&gt;% gather(variable, valor, expend:sat) %&gt;% group_by(variable) %&gt;% summarise(cuantiles = list(cuantil(valor))) %&gt;% unnest(cols = c(cuantiles)) %&gt;% mutate(valor = round(valor, 1)) %&gt;% spread(cuantil, valor) sat_tbl %&gt;% formatear_tabla variable 0 0.25 0.5 0.75 1 expend 3.7 4.9 5.8 6.4 9.8 sat 844.0 897.2 945.5 1032.0 1107.0 Esta variaci√≥n es considerable para promedios del SAT: el percentil 75 es alrededor de 1050 puntos, mientras que el percentil 25 corresponde a alrededor de 800. Igualmente, hay diferencias considerables de gasto por alumno (miles de d√≥lares) a lo largo de los estados. Ahora hacemos nuestro primer ejercico de comparaci√≥n: ¬øC√≥mo se ven las calificaciones para estados en distintos niveles de gasto? Podemos usar una gr√°fica de dispersi√≥n: library(ggrepel) ggplot(sat, aes(x = expend, y = sat, label = state)) + geom_point(colour = &quot;red&quot;, size = 2) + geom_text_repel(colour = &quot;gray50&quot;) + xlab(&quot;Gasto por alumno (miles de d√≥lares)&quot;) + ylab(&quot;Calificaci√≥n promedio en SAT&quot;) Estas comparaciones no son de alta calidad, solo estamos usando 2 variables ‚Äîque son muy pocas‚Äî y no hay mucho que podamos decir en cuanto explicaci√≥n. Sin duda nos hace falta una imagen m√°s completa. Necesitar√≠amos entender la correlaci√≥n que existe entre las dem√°s caracter√≠sticas de nuestras unidades de estudio. Las unidades que estamos comparando pueden diferir fuertemente en otras propiedades importantes (aka, dimensiones), lo cual no permite interpretar la gr√°fica de manera sencilla. Sabemos que es posible que el IQ difiera en los estados. Pero no sabemos c√≥mo producir diferencias de este tipo. Sin embargo, ¬°descubrimos que existe una variable adicional! √âsta es el porcentaje de alumnos de cada estado que toma el SAT. Podemos agregar como sigue: ggplot(sat, aes(x = expend, y = math, label=state, colour = frac)) + geom_point() + geom_text_repel() + xlab(&quot;Gasto por alumno (miles de d√≥lares)&quot;) + ylab(&quot;Calificaci√≥n en matem√°ticas&quot;) Esto nos permite entender por qu√© nuestra comparaci√≥n inicial es relativamente pobre. Los estados con mejores resultados promedio en el SAT son aquellos donde una fracci√≥n relativamente baja de los estudiantes toma el examen. La diferencia es considerable. En este punto podemos hacer varias cosas. Una primera idea es intentar comparar estados m√°s similares en cuanto a la poblaci√≥n de alumnos que asiste. Podr√≠amos hacer grupos como sigue: set.seed(991) k_medias_sat &lt;- kmeans(sat %&gt;% select(frac), centers = 4, nstart = 100, iter.max = 100) sat$clase &lt;- k_medias_sat$cluster sat &lt;- sat %&gt;% group_by(clase) %&gt;% mutate(clase_media = round(mean(frac))) %&gt;% ungroup %&gt;% mutate(clase_media = factor(clase_media)) sat &lt;- sat %&gt;% mutate(rank_p = rank(frac, ties= &quot;first&quot;) / length(frac)) ggplot(sat, aes(x = rank_p, y = frac, label = state, colour = clase_media)) + geom_point(size = 2) Estos resultados indican que es m√°s probable que buenos alumnos decidan hacer el SAT. Lo interesante es que esto ocurre de manera diferente en cada estado. Por ejemplo, en algunos estados era m√°s com√∫n otro examen: el ACT. Si hacemos clusters de estados seg√∫n el % de alumnos, empezamos a ver otra historia. Para esto, ajustemos rectas de m√≠nimos cuadrados como referencia: Sin embargo, el resultado puede variar considerablemente si categorizamos de distintas maneras. Tablas de conteos Consideremos los siguientes datos de tomadores de t√© (del paquete FactoMineR (L√™, Josse, and Husson 2008)): tea &lt;- read_csv(&quot;data/tea.csv&quot;) # nombres y c√≥digos te &lt;- tea %&gt;% select(how, price, sugar) %&gt;% rename(presentacion = how, precio = price, azucar = sugar) %&gt;% mutate( presentacion = fct_recode(presentacion, suelto = &quot;unpackaged&quot;, bolsas = &quot;tea bag&quot;, mixto = &quot;tea bag+unpackaged&quot;), precio = fct_recode(precio, marca = &quot;p_branded&quot;, variable = &quot;p_variable&quot;, barato = &quot;p_cheap&quot;, marca_propia = &quot;p_private label&quot;, desconocido = &quot;p_unknown&quot;, fino = &quot;p_upscale&quot;), azucar = fct_recode(azucar, sin_az√∫car = &quot;No.sugar&quot;, con_az√∫car = &quot;sugar&quot;)) sample_n(te, 10) ## [90m# A tibble: 10 x 3[39m ## presentacion precio azucar ## [3m[90m&lt;fct&gt;[39m[23m [3m[90m&lt;fct&gt;[39m[23m [3m[90m&lt;fct&gt;[39m[23m ## [90m 1[39m mixto variable sin_az√∫car ## [90m 2[39m suelto fino con_az√∫car ## [90m 3[39m bolsas fino con_az√∫car ## [90m 4[39m mixto variable sin_az√∫car ## [90m 5[39m bolsas variable sin_az√∫car ## [90m 6[39m suelto variable con_az√∫car ## [90m 7[39m bolsas variable con_az√∫car ## [90m 8[39m mixto fino sin_az√∫car ## [90m 9[39m bolsas marca con_az√∫car ## [90m10[39m mixto marca sin_az√∫car Nos interesa ver qu√© personas compran t√© suelto, y de qu√© tipo. Empezamos por ver las proporciones que compran t√© seg√∫n su empaque (en bolsita o suelto): precio &lt;- te %&gt;% count(precio) %&gt;% mutate(prop = round(100 * n / sum(n))) %&gt;% select(-n) tipo &lt;- te %&gt;% group_by(presentacion) %&gt;% tally() %&gt;% mutate(pct = round(100 * n / sum(n))) tipo %&gt;% formatear_tabla presentacion n pct bolsas 170 57 mixto 94 31 suelto 36 12 La mayor parte de las personas toma t√© en bolsas. Sin embargo, el tipo de t√© (en t√©rminos de precio o marca) que compran es muy distinto dependiendo de la presentaci√≥n: tipo &lt;- tipo %&gt;% select(presentacion, prop_presentacion = pct) tabla_cruzada &lt;- te %&gt;% count(presentacion, precio) %&gt;% # porcentajes por presentaci√≥n group_by(presentacion) %&gt;% mutate(prop = round(100 * n / sum(n))) %&gt;% select(-n) tabla_cruzada %&gt;% pivot_wider(names_from = presentacion, values_from = prop, values_fill = list(prop = 0)) %&gt;% formatear_tabla() precio bolsas mixto suelto marca 41 21 14 barato 3 1 3 marca_propia 9 4 3 desconocido 6 1 0 fino 8 20 56 variable 32 52 25 Estos datos podemos examinarlos un rato y llegar a conclusiones. Notemos que el uso de tablas no permite mostrar claramente patrones. Tampoco por medio de gr√°ficas como la siguiente: ggplot(tabla_cruzada %&gt;% ungroup %&gt;% mutate(price = fct_reorder(precio, prop)), aes(x = precio, y = prop, group = presentacion, colour = presentacion)) + geom_point() + coord_flip() + geom_line() En lugar de eso, calcularemos perfiles columna. Esto es, comparamos cada una de las columnas con la columna marginal (en la tabla de tipo de estilo de t√©): num_grupos &lt;- n_distinct(te %&gt;% select(presentacion)) tabla &lt;- te %&gt;% count(presentacion, precio) %&gt;% group_by(presentacion) %&gt;% mutate(prop_precio = (100 * n / sum(n))) %&gt;% group_by(precio) %&gt;% mutate(prom_prop = sum(prop_precio)/num_grupos) %&gt;% mutate(perfil = 100 * (prop_precio / prom_prop - 1)) tabla ## [90m# A tibble: 17 x 6[39m ## [90m# Groups: precio [6][39m ## presentacion precio n prop_precio prom_prop perfil ## [3m[90m&lt;fct&gt;[39m[23m [3m[90m&lt;fct&gt;[39m[23m [3m[90m&lt;int&gt;[39m[23m [3m[90m&lt;dbl&gt;[39m[23m [3m[90m&lt;dbl&gt;[39m[23m [3m[90m&lt;dbl&gt;[39m[23m ## [90m 1[39m bolsas marca 70 41.2 25.4 61.8 ## [90m 2[39m bolsas barato 5 2.94 2.26 30.1 ## [90m 3[39m bolsas marca_propia 16 9.41 5.48 71.7 ## [90m 4[39m bolsas desconocido 11 6.47 2.51 158. ## [90m 5[39m bolsas fino 14 8.24 28.0 -[31m70[39m[31m.[39m[31m6[39m ## [90m 6[39m bolsas variable 54 31.8 36.3 -[31m12[39m[31m.[39m[31m5[39m ## [90m 7[39m mixto marca 20 21.3 25.4 -[31m16[39m[31m.[39m[31m4[39m ## [90m 8[39m mixto barato 1 1.06 2.26 -[31m52[39m[31m.[39m[31m9[39m ## [90m 9[39m mixto marca_propia 4 4.26 5.48 -[31m22[39m[31m.[39m[31m4[39m ## [90m10[39m mixto desconocido 1 1.06 2.51 -[31m57[39m[31m.[39m[31m6[39m ## [90m11[39m mixto fino 19 20.2 28.0 -[31m27[39m[31m.[39m[31m8[39m ## [90m12[39m mixto variable 49 52.1 36.3 43.6 ## [90m13[39m suelto marca 5 13.9 25.4 -[31m45[39m[31m.[39m[31m4[39m ## [90m14[39m suelto barato 1 2.78 2.26 22.9 ## [90m15[39m suelto marca_propia 1 2.78 5.48 -[31m49[39m[31m.[39m[31m3[39m ## [90m16[39m suelto fino 20 55.6 28.0 98.4 ## [90m17[39m suelto variable 9 25 36.3 -[31m31[39m[31m.[39m[31m1[39m tabla_perfil &lt;- tabla %&gt;% select(presentacion, precio, perfil, pct = prom_prop) %&gt;% pivot_wider(names_from = presentacion, values_from = perfil, values_fill = list(perfil = -100.0)) if_profile &lt;- function(x){ any(x &lt; 0) &amp; any(x &gt; 0) } marcar &lt;- marcar_tabla_fun(25, &quot;red&quot;, &quot;black&quot;) tab_out &lt;- tabla_perfil %&gt;% arrange(desc(bolsas)) %&gt;% select(-pct, everything()) %&gt;% mutate(across(where(is.numeric), round)) %&gt;% mutate(across(where(if_profile), marcar)) %&gt;% knitr::kable(format_table_salida(), escape = FALSE, booktabs = T) %&gt;% kableExtra::kable_styling(latex_options = c(&quot;striped&quot;, &quot;scale_down&quot;), bootstrap_options = c( &quot;hover&quot;, &quot;condensed&quot;), full_width = FALSE) if (knitr::is_latex_output()) { gsub(&quot;marca_propia&quot;, &quot;marca-propia&quot;, tab_out) } else { tab_out } precio bolsas mixto suelto pct desconocido 158 -58 -100 3 marca_propia 72 -22 -49 5 marca 62 -16 -45 25 barato 30 -53 23 2 variable -12 44 -31 36 fino -71 -28 98 28 Leemos esta tabla como sigue: por ejemplo, los compradores de t√© suelto compran t√© fino a una tasa casi el doble (98%) que el promedio. Tambi√©n podemos graficar como: tabla_graf &lt;- tabla_perfil %&gt;% ungroup %&gt;% mutate(precio = fct_reorder(precio, bolsas)) %&gt;% select(-pct) %&gt;% pivot_longer(cols = -precio, names_to = &quot;presentacion&quot;, values_to = &quot;perfil&quot;) g_perfil &lt;- ggplot(tabla_graf, aes(x = precio, xend = precio, y = perfil, yend = 0, group = presentacion)) + geom_point() + geom_segment() + facet_wrap(~presentacion) + geom_hline(yintercept = 0 , colour = &quot;gray&quot;)+ coord_flip() g_perfil Observaci√≥n: hay dos maneras de construir la columna promedio: tomando los porcentajes sobre todos los datos, o promediando los porcentajes de las columnas. Si los grupos de las columnas est√°n desbalanceados, estos promedios son diferentes. Cuando usamos porcentajes sobre la poblaci√≥n, perfiles columna y rengl√≥n dan el mismo resultado Sin embargo, cuando hay un grupo considerablemente m√°s grande que otros, las comparaciones se vuelven vs este grupo particular. No siempre queremos hacer esto. Interpretaci√≥n En el √∫ltimo ejemplo de tomadores de t√© utilizamos una muestra de personas, no toda la poblaci√≥n de tomadores de t√©. Eso quiere decir que tenemos cierta incertidumbre de c√≥mo se generalizan o no los resultados que obtuvimos en nuestro an√°lisis a la poblaci√≥n general. Nuestra respuesta depende de c√≥mo se extrajo la muestra que estamos considerando. Si el mecanismo de extracci√≥n incluye alg√∫n proceso probabil√≠stico, entonces es posible en principio entender qu√© tan bien generalizan los resultados de nuestro an√°lisis a la poblaci√≥n general, y entender esto depende de entender qu√© tanta variaci√≥n hay de muestra a muestra, de todas las posibles muestras que pudimos haber extraido. En las siguiente secciones discutiremos estos aspectos, en los cuales pasamos del trabajo de ‚Äúdetective‚Äù al trabajo de ‚Äújuez‚Äù en nuestro trabajo anal√≠tico. Loess Las gr√°ficas de dispersi√≥n son la herramienta b√°sica para describir la relaci√≥n entre dos variables cuantitativas, y como vimos en ejemplo anteriores, muchas veces podemos apreciar mejor la relaci√≥n entre ellas si agregamos una curva loess que suavice. Los siguientes datos muestran los premios ofrecidos y las ventas totales de una loter√≠a a lo largo de 53 sorteos (las unidades son cantidades de dinero indexadas). Graficamos en escalas logar√≠tmicas y agregamos una curva loess. # cargamos los datos load(here::here(&quot;data&quot;, &quot;ventas_sorteo.Rdata&quot;)) ggplot(ventas.sorteo, aes(x = log(premio), y = log(ventas.tot.1))) + geom_point() + geom_smooth(method = &quot;loess&quot;, alpha = 0.5, method.args = list(degree = 1), se = FALSE) ## `geom_smooth()` using formula &#39;y ~ x&#39; El patr√≥n no era dif√≠cil de ver en los datos originales, sin embargo, la curva lo hace m√°s claro, el logaritmo de las ventas tiene una relaci√≥n no lineal con el logaritmo del premio: para premios no muy grandes no parece haber gran diferencia, pero cuando los premios empiezan a crecer por encima de 20,000 (aproximadamente \\(e^{10}\\)), las ventas crecen m√°s r√°pidamente que para premios menores. Este efecto se conoce como bola de nieve, y es frecuente en este tipo de loter√≠as. Antes de adentrarnos a loess comenzamos explicando c√≥mo se ajustan familias param√©tricas de curvas a conjuntos de datos dados. Ajustando familias param√©tricas. Supongamos que tenemos la familia \\(f_{a,b}=ax+b\\) y datos bivariados \\((x_1,y_1), ..., (x_n, y_n)\\). Buscamos encontrar \\(a\\) y \\(b\\) tales que \\(f_{a,b}\\) de un ajuste √≥ptimo a los datos. El criterio de m√≠nimos cuadrados consiste en encontrar \\(a\\), \\(b\\) que minimicen la suma de cuadrados: \\[\\sum_{i=1}^n(y_i-ax_i-b)^2\\] En este caso, las constantes \\(a\\) y \\(b\\) se pueden encontrar diferenciando esta funci√≥n objetivo. M√°s a√∫n, estamos ajustando una recta a los datos, pero podemos repetir el argumento con otras familias de funciones (por ejemplo cuadr√°ticas). ggplot(ventas.sorteo, aes(x = log(premio), y = log(ventas.tot.1))) + geom_point() + geom_smooth(method = &quot;lm&quot;) ## `geom_smooth()` using formula &#39;y ~ x&#39; Donde los par√°metros \\(a\\) y \\(b\\) est√°n dados por: mod_lineal &lt;- lm(log(ventas.tot.1) ~ log(premio), data = ventas.sorteo) round(coef(mod_lineal), 2) ## (Intercept) log(premio) ## 4.56 0.47 De modo que la curva ajustada es \\(\\log(V) = 4.6 + 0.47 \\log(P)\\), o en las unidades originales \\(V = 100 P^{0.47}\\), donde \\(V\\) son las ventas y \\(P\\) el premio. Si observamos la gr√°fica notamos que este modelo lineal (en los logaritmos) no es adecuado para estos datos. Podr√≠amos experimentar con otras familias (por ejemplo, una cuadr√°tica o c√∫bica, potencias, exponenciales, etc.); sin embargo, en la etapa exploratoria es mejor tomar una ruta de ajuste m√°s flexibles (a√∫n cuando esta no sea con funciones algebr√°icas), que al mismo tiempo sea robusto. Observaci√≥n: Los modelos de regresi√≥n lineal, cuando se pueden ajustar de manera razonable, son altamente deseables por su simplicidad: los datos se describen con pocos par√°metros y tenemos incrementos marginales constantes en todo el rango de la variable que juega como factor, de modo que la interpretaci√≥n es simple. Por esta raz√≥n, muchas veces vale la pena transformar los datos con el fin de enderezar la relaci√≥n de dos variables y poder ajustar una funci√≥n lineal. Ajustando curvas loess La idea es producir ajustes locales de rectas o funciones cuadr√°ticas. En estas familias es necesario especificar dos par√°metros: Par√°metro de suavizamiento \\(\\alpha\\): cuando \\(\\alpha\\) es m√°s grande, la curva ajustada es m√°s suave. Grado de los polinomios locales que ajustamos \\(\\lambda\\): generalmente se toma \\(\\lambda=1,2\\). Entonces, supongamos que los datos est√°n dados por \\((x_1,y_1), ..., (x_n, y_n)\\), y sean \\(\\alpha\\) un par√°metro de suavizamiento fijo, y \\(\\lambda=1\\). Denotamos como \\(\\hat{g}(x)\\) la curva loess ajustada, y como \\(w_i(x)\\) a una funci√≥n de peso (que depende de x) para la observaci√≥n \\((x_i, y_i)\\). Para poder calcular \\(w_i(x)\\) debemos comenzar calculando \\(q=\\lfloor{n\\alpha}\\rfloor\\) que suponemos mayor que uno. Ahora definimos la funci√≥n tricubo: \\[ \\begin{equation} T(u)=\\begin{cases} (1-|u|^3)^3, &amp; \\text{para $|u| &lt; 1$}.\\\\ 0, &amp; \\text{en otro caso}. \\end{cases} \\end{equation} \\] entonces, para el punto \\(x\\) definimos el peso correspondiente al dato \\((x_i,y_i)\\), denotado por \\(w_i(x)\\) como: \\[w_i(x)=T\\bigg(\\frac{|x-x_i|}{d_q(x)}\\bigg)\\] donde \\(d_q(x)\\) es el valor de la \\(q-√©sima\\) distancia m√°s chica (la m√°s grande entre las \\(q\\) m√°s chicas) entre los valores \\(|x-x_j|\\), \\(j=1,2,...,n\\). De esta forma, las observaciones \\(x_i\\) reciben m√°s peso cuanto m√°s cerca est√©n de \\(x\\). En palabras, de \\(x_1,...,x_n\\) tomamos los \\(q\\) datos m√°s cercanos a \\(x\\), que denotamos \\(x_{i_1}(x) \\leq x_{i_2}(x) \\leq \\cdots x_{i_q}(x) \\leq\\). Los re-escalamos a \\([0,1]\\) haciendo corresponder \\(x\\) a \\(0\\) y el punto m√°s alejado de \\(x\\) (que es \\(x_{i_q}\\)) a 1. Aplicamos el tricubo (gr√°fica de abajo), para encontrar los pesos de cada punto. Los puntos que est√°n a una distancia mayor a \\(d_q(x)\\) reciben un peso de cero, y los m√°s cercanos un peso que depende de que tan cercanos est√°n a \\(x\\). tricubo &lt;- function(x) { ifelse(abs(x) &lt; 1, (1 - abs(x) ^ 3) ^ 3, 0) } curve(tricubo, from = -1.5, to = 1.5) Finalmente ajustamos una recta de m√≠nimos cuadrados ponderados por los pesos \\(w_i(x)\\), es decir, minimizamos \\[\\sum_{i=1}^nw_i(x)(y_i-ax_i-b)^2\\] Hacemos esto para cada valor de \\(x\\) que est√° en el rango de los datos \\(x_1,...,x_n\\). Observaciones: Cualquier funci√≥n con la forma de flan del tricubo (se desvanece fuera de \\((-1,1)\\), es creciente en \\((-1,0)\\) y decreciente en \\((0, 1)\\), adem√°s de ser continua y quiz√°s diferenciable) es un buen candidato para usar en lugar del tricubo. La raz√≥n por la que escogemos precisamente esta forma algebr√°ica no tiene que ver con el an√°lisis exploratorio, sino con las ventajas te√≥ricas adicionales que tiene en la inferencia. El caso \\(\\lambda=2\\) es similar. La √∫nica diferencia es en el paso de ajuste, donde usamos funciones cuadr√°ticas, y obtendr√≠amos entonces tres par√°metros \\(a(x), b(x), c(x)\\). Escogiendo de los par√°metros. Los par√°metros \\(\\alpha\\) y \\(\\lambda\\) se encuentran por ensayo y error. La idea general es que debemos encontrar una curva que explique patrones importantes en los datos (que ajuste los datos) pero que no muestre variaciones a escalas m√°s chicas dif√≠ciles de explicar (que pueden ser el resultado de influencias de otras variables, variaci√≥n muestral, ruido o errores de redondeo, por ejemplo). En el proceso de prueba y error iteramos el ajuste y en cada paso hacemos an√°lisis de residuales, con el fin de seleccionar un suavizamiento adecuado. Ejemplo de distintas selecciones de \\(\\lambda\\), en este ejemplo consideramos la ventas semanales de un producto a lo largo de 5 a√±os. Series de tiempo Podemos usar el suavizamiento loess para entender y describir el comportamiento de series de tiempo, en las cu√°les intentamos entender la dependencia de una serie de mediciones indexadas por el tiempo. T√≠picamente es necesario utilizar distintas componentes para describir exitosamente una serie de tiempo, y para esto usamos distintos tipos de suavizamientos. Veremos que distintas componentes var√≠an en distintas escalas de tiempo (unas muy lentas, cono la tendencia, otras m√°s rapidamente, como variaci√≥n quincenal, etc.). Caso de estudio: nacimientos en M√©xico Este caso de estudio esta basado en un an√°lisis propuesto por A. Vehtari y A. Gelman, junto con un an√°lisis de serie de tiempo de Cleveland (1993). En nuestro caso, usaremos los datos de nacimientos registrados por d√≠a en M√©xico desde 1999. Los usaremos para contestar las preguntas: ¬øcu√°les son los cumplea√±os m√°s frecuentes? y ¬øen qu√© mes del a√±o hay m√°s nacimientos? Podr√≠amos utilizaar una gr√°fica popular (ver por ejemplo esta visualizaci√≥n) como: Sin embargo, ¬øc√≥mo criticar√≠as este an√°lisis desde el punto de vista de los tres primeros principios del dise√±o anal√≠tico? ¬øLas comparaciones son √∫tiles? ¬øHay aspectos multivariados? ¬øQu√© tan bien explica o sugiere estructura, mecanismos o causalidad? Datos de natalidad para M√©xico library(lubridate) library(ggthemes) theme_set(theme_minimal(base_size = 14)) natalidad &lt;- readRDS(&quot;./data/nacimientos/natalidad.rds&quot;) %&gt;% mutate(dia_semana = weekdays(fecha)) %&gt;% mutate(dia_a√±o = yday(fecha)) %&gt;% mutate(a√±o = year(fecha)) %&gt;% mutate(mes = month(fecha)) %&gt;% ungroup %&gt;% mutate(dia_semana = recode(dia_semana, Monday = &quot;Lunes&quot;, Tuesday = &quot;Martes&quot;, Wednesday = &quot;Mi√©rcoles&quot;, Thursday = &quot;Jueves&quot;, Friday = &quot;Viernes&quot;, Saturday = &quot;S√°bado&quot;, Sunday = &quot;Domingo&quot;)) %&gt;% mutate(dia_semana = fct_relevel(dia_semana, c(&quot;Lunes&quot;, &quot;Martes&quot;, &quot;Mi√©rcoles&quot;, &quot;Jueves&quot;, &quot;Viernes&quot;, &quot;S√°bado&quot;, &quot;Domingo&quot;))) Consideremos los datos agregados del n√∫mero de nacimientos (registrados) por d√≠a desde 1999 hasta 2016. Un primer intento podr√≠a ser hacer una gr√°fica de la serie de tiempo. Sin embargo, vemos que no es muy √∫til: Hay varias caracter√≠sticas que notamos. Primero, parece haber una tendencia ligeramente decreciente del n√∫mero de nacimientos a lo largo de los a√±os. Segundo, la gr√°fica sugiere un patr√≥n anual. Y por √∫ltimo, encontramos que hay dispersi√≥n producida por los d√≠as de la semana. S√≥lo estas caracter√≠sticas hacen que la comparaci√≥n entre d√≠as sea dif√≠cil de realizar. Supongamos que comparamos el n√∫mero de nacimientos de dos mi√©rcoles dados. Esa comparaci√≥n ser√° diferente dependiendo: del a√±o donde ocurrieron, el mes donde ocurrieron, si semana santa ocurri√≥ en algunos de los mi√©rcoles, y as√≠ sucesivamente. Como en nuestros ejemplos anteriores, la idea del siguiente an√°lisis es aislar las componentes que observamos en la serie de tiempo: extraemos componentes ajustadas, y luego examinamos los residuales. En este caso particular, asumiremos una descomposici√≥n aditiva de la serie de tiempo (Cleveland 1993). En el estudio de series de tiempo una estructura com√∫n es considerar el efecto de diversos factores como tendencia, estacionalidad, ciclicidad e irregularidades de manera aditiva. Esto es, consideramos la descomposici√≥n \\[\\begin{align} y(t) = f_{t}(t) + f_{e}(t) + f_{c}(t) + \\varepsilon. \\end{align}\\] Una estrategia de ajuste, como veremos m√°s adelante, es proceder de manera modular. Es decir, se ajustan los componentes de manera secuencial considerando los residuales de los anteriores. Tendencia Comenzamos por extraer la tendencia, haciendo promedios loess (Cleveland 1979) con vecindades relativamente grandes. Quiz√° preferir√≠amos suavizar menos para capturar m√°s variaci√≥n lenta, pero si hacemos esto en este punto empezamos a absorber parte de la componente anual: mod_1 &lt;- loess(n ~ as.numeric(fecha), data = natalidad, span = 0.2, degree = 1) datos_dia &lt;- natalidad %&gt;% mutate(ajuste_1 = fitted(mod_1)) %&gt;% mutate(res_1 = n - ajuste_1) Notemos que a principios de 2000 el suavizador est√° en niveles de alrededor de 7000 nacimientos diarios, hacia 2015 ese n√∫mero es m√°s cercano a unos 6000. Componente anual Al obtener la tendencia podemos aislar el efecto a largo plazo y proceder a realizar mejores comparaciones (por ejemplo, comparar un d√≠a de 2000 y de 2015 tendria m√°s sentido). Ahora, ajustamos los residuales del suavizado anterior, pero con menos suavizamiento. As√≠ evitamos capturar tendencia: mod_anual &lt;- loess(res_1 ~ as.numeric(fecha), data = datos_dia, degree = 2, span = 0.005) datos_dia &lt;- datos_dia %&gt;% mutate(ajuste_2 = fitted(mod_anual)) %&gt;% mutate(res_2 = res_1 - ajuste_2) D√≠a de la semana Hasta ahora, hemos aislado los efectos por plazos largos de tiempo (tendencia) y hemos incorporado las variaciones estacionales (componente anual) de nuestra serie de tiempo. Ahora, veremos c√≥mo capturar el efecto por d√≠a de la semana. En este caso, podemos hacer suavizamiento loess para cada serie de manera independiente datos_dia &lt;- datos_dia %&gt;% group_by(dia_semana) %&gt;% nest() %&gt;% mutate(ajuste_mod = map(data, ~ loess(res_2 ~ as.numeric(fecha), data = .x, span = 0.1, degree = 1))) %&gt;% mutate(ajuste_3 = map(ajuste_mod, fitted)) %&gt;% select(-ajuste_mod) %&gt;% unnest(cols = c(data, ajuste_3)) %&gt;% mutate(res_3 = res_2 - ajuste_3) %&gt;% ungroup Residuales Por √∫ltimo, examinamos los residuales finales quitando los efectos ajustados: ## `geom_smooth()` using formula &#39;y ~ x&#39; Observaci√≥n: n√≥tese que la distribuci√≥n de estos residuales presenta irregularidades interesantes. La distribuci√≥n es de colas largas, y no se debe a unos cuantos datos at√≠picos. Esto generalmente es indicaci√≥n que hay factores importantes que hay que examinar mas a detalle en los residuales: Reestimaci√≥n Cuando hacemos este proceso secuencial de llevar el ajuste a los residual, a veces conviene iterarlo. La raz√≥n es que un una segunda o tercera pasada podemos hacer mejores estimaciones de cada componente, y es posible suavizar menos sin capturar componentes de m√°s alta frecuencia. As√≠ que podemos regresar a la serie original para hacer mejores estimaciones, m√°s suavizadas: # Quitamos componente anual y efecto de d√≠a de la semana datos_dia &lt;- datos_dia %&gt;% mutate(n_1 = n - ajuste_2 - ajuste_3) # Reajustamos mod_1 &lt;- loess(n_1 ~ as.numeric(fecha), data = datos_dia, span = 0.02, degree = 2, family = &quot;symmetric&quot;) Y ahora repetimos con la componente de d√≠a de la semana: An√°lisis de componentes Ahora comparamos las componentes estimadas y los residuales en una misma gr√°fica. Por definici√≥n, la suma de todas estas componentes da los datos originales. Este √∫ltimo paso nos permite diversas comparaciones que explican la variaci√≥n que vimos en los datos. Una gran parte de los residuales est√° entre \\(\\pm 250\\) nacimientos por d√≠a. Sin embargo, vemos que las colas tienen una dispersi√≥n mucho mayor: quantile(datos_dia$res_6, c(00, .01,0.05, 0.10, 0.90, 0.95, 0.99, 1)) %&gt;% round ## 0% 1% 5% 10% 90% 95% 99% 100% ## -2238 -1134 -315 -202 188 268 516 2521 ¬øA qu√© se deben estas colas tan largas? Viernes 13? Podemos empezar con una curosidad: en viernes o martes 13, ¬ønacen menos ni√±os? N√≥tese que fue √∫til agregar el indicador de Semana santa por el Viernes 13 de Semana Santa que se ve como un at√≠pico en el panel de los viernes 13. Residuales: antes y despu√©s de 2006 Veamos primero una agregaci√≥n sobre los a√±os de los residuales. Lo primero es observar un cambio que sucedi√≥ repentinamente en 2006: La raz√≥n es un cambio en la ley acerca de cu√°ndo pueden entrar los ni√±os a la primaria. Antes era por edad y hab√≠a poco margen. Ese exceso de nacimientos son reportes falsos para que los ni√±os no tuvieran que esperar un a√±o completo por haber nacido unos cuantos d√≠as antes de la fecha l√≠mite. Otras caracter√≠sticas que debemos investigar: Efectos de A√±o Nuevo, Navidad, Septiembre 16 y otros d√≠as feriados como Febrero 14. Semana santa: como la fecha cambia, vemos que los residuales negativos tienden a ocurrir dispersos alrededor del d√≠a 100 del a√±o. Otros d√≠as especiales: m√°s de residuales Ahora promediamos residuales (es posible agregar barras para indicar dispersi√≥n a lo largo de los a√±os) para cada d√≠a del a√±o. Podemos identificar ahora los residuales m√°s grandes: se deben, por ejemplo, a d√≠as feriados, con consecuencias adicionales que tienen en d√≠as ajuntos (excesos de nacimientos): ## `summarise()` regrouping output by &#39;dia_a√±o_366&#39;, &#39;antes_2006&#39; (override with `.groups` argument) Semana santa Para Semana Santa tenemos que hacer unos c√°lculos. Si alineamos los datos por d√≠as antes de Domingo de Pascua, obtenemos un patr√≥n de ca√≠da fuerte de nacimientos el Viernes de Semana Santa, y la caracter√≠stica forma de ‚Äúvalle con hombros‚Äù en d√≠as anteriores y posteriores estos Viernes. ¬øPor qu√© ocurre este patr√≥n? ## `geom_smooth()` using formula &#39;y ~ x&#39; N√≥tese un defecto de nuestro modelo: el patr√≥n de ‚Äúhombros‚Äù alrededor del Viernes Santo no es suficientemente fuerte para equilibrar los nacimientos faltantes. ¬øC√≥mo podr√≠amos mejorar nuestra descomposici√≥n? Referencias "],
["tipos-de-estudio-y-experimentos.html", "Secci√≥n 3 Tipos de estudio y experimentos Muestreo aleatorio Pero si no podemos hacer muestreo aleatorio? El estimador est√°ndar Experimentos tradicionales Bloqueo Variables desconocidas Aleatorizando el tratamiento Resumen: selecci√≥n de unidades y tratamiento Asignaci√≥n natural del tratamiento", " Secci√≥n 3 Tipos de estudio y experimentos Motivaci√≥n Pregunta de entrevista de Google (Chihara and Hesterberg 2018) Imagina que eres consultor y te preguntan lo siguiente (ver siguiente figura): Estoy haciendo una comparaci√≥n de antes y despu√©s donde la hip√≥tesis alternativa es pre.media.error &gt; post.media.error. La distribuci√≥n de ambas muestras es sesgada a la derecha. ¬øQu√© prueba me recomiendas para √©sta situaci√≥n? Figure 3.1: Error CPR, gr√°fica de densidad. La siguiente imagen Roger Peng representa una situaci√≥n com√∫n a la que se enfrenta el analista de datos, y se desarroll√≥ en el contexto de preguntas vagas. En el esquema hay tres caminos: uno es uno ideal que pocas veces sucede, otro produce respuestas poco √∫tiles pero es f√°cil, y otro es tortuoso pero que caracteriza el mejor trabajo de an√°lisis de datos: Figure 3.2: Adaptado de R. Peng: Tukey, design thinking and better questions. Ejemplos: Alguien nos pregunta cu√°les son las tiendas que mas venden de una cadena. Podr√≠amos consultar bases de datos, hacer extracciones, definir periodos, etc. y dar una respuesta que probablemente es poco √∫til. Nos damos cuenta, por ejemplo, porque la peor tienda es una que abri√≥ hace relativamente poco, y la mejor es una de las tiendas m√°s grandes que est√° en una zona de tr√°fico de alto costo. Una pregunta m√°s interesante es, ¬øqu√© equipos de ventas tienen mejor desempe√±o? ¬øCu√°nto aporta tener una cafeter√≠a dentro de la tienda en t√©rminos de ventas?, etc. Proceso Generador de Datos Entre las preguntas que se debe hacer el analista de datos una fundamental es entender el proceso generador de datos, pues esto determinar√° que otras preguntas son relevantes, tanto en t√©rminos pr√°cticos como estad√≠sticos. La inferencia estad√≠stica busca hacer afirmaciones, cuantificadas de manera probabilista, acerca de datos que no tenemos, usando regularidades y conocimiento de datos que s√≠ tenemos disponibles y m√©todos cuantitativos. Para hacer afirmaciones inferenciales eficientes y bien calibradas (con garant√≠as estad√≠sticas de calibraci√≥n) a preguntas donde queremos generalizar de muestra a poblaci√≥n, se requiere conocer con precisi√≥n el proceso que genera los datos muestrales. Esto incluye saber con detalle c√≥mo se seleccionaron los datos a partir de los que se quiere hacer inferencia. En este caso, eficiente quiere decir que aprovechamos toda la informaci√≥n que est√° en los datos observados de manera que nuestros rangos de incertidumbre son lo m√°s chico posibles (adem√°s de estar correctamente calibrados). Por su parte, probabil√≠sticamente bien calibrados se refiere a que, lo que decimos que puede ocurrir con 10% de probabilidad ocurre efectivamente 1 de cada 10 veces, si decimos 20% entonces ocurre 2 de 20, etc. Veremos que para muestras dadas naturalmente, a veces es muy difi√≠cil entender a fondo el proceso generaci√≥n de la muestra. Ejemplo: Prevalencia de anemia Supongamos que nos interesa conocer el porcentaje de menores en edad escolar, (entre 6 y 15 a√±os), con anemia en M√©xico. La fuente de datos disponible corresponde a registros de del IMSS de hospitalizaciones de menores, ya sea por anemia o que por otra causa (infecciones gastrointestinales, apendicitis, tratamiento de leucemia, ‚Ä¶), se registr√≥ si el menor ten√≠a anemia. En nuestra muestra el 47% de los ni√±os tiene anemia. head(paciente) ## [90m# A tibble: 6 x 4[39m ## edad padecimiento sexo anemia ## [3m[90m&lt;int&gt;[39m[23m [3m[90m&lt;chr&gt;[39m[23m [3m[90m&lt;chr&gt;[39m[23m [3m[90m&lt;int&gt;[39m[23m ## [90m1[39m 8 picadura alacr√°n mujer 0 ## [90m2[39m 10 infecci√≥n intestinal hombre 1 ## [90m3[39m 7 mordedura de perro hombre 1 ## [90m4[39m 8 asma hombre 1 ## [90m5[39m 13 infecci√≥n intestinal mujer 0 ## [90m6[39m 7 picadura alacr√°n hombre 0 ¬øQu√© nos dice esta cantidad acerca de la anemia en la poblaci√≥n? ¬øPodemos hacer inferencia estad√≠stica? ¬øC√≥mo calculamos intervalos de confianza? # Si calculo el error est√°ndar de la p estimada como sigue, es correcto? p &lt;- mean(paciente$anemia) sqrt(p * (1 - p) / 5000) ## [1] 0.007060751 Muestreo aleatorio En la situaci√≥n ideal dise√±ar√≠amos una muestra aleatoria de menores de edad, por ejemplo, utilizando el registro en educaci√≥n primaria de la SEP, y medir√≠amos la prevalencia de anemia en la muestra, usar√≠amos esta muestra para estimar la prevalencia en la poblaci√≥n y tendr√≠amos adem√°s las herramientas para medir la incertidumbre de nuestra estimaci√≥n (reportar intervalos, o errores est√°ndar). Pero si no podemos hacer muestreo aleatorio? En el caso de prevalencia de anemia, discutiendo con m√©dicos e investigadores nos informan que la anemia se presenta en tasas m√°s altas en ni√±os m√°s chicos. paciente %&gt;% count(edad) %&gt;% mutate(prop = round(100 * n / sum(n))) ## [90m# A tibble: 10 x 3[39m ## edad n prop ## [3m[90m&lt;int&gt;[39m[23m [3m[90m&lt;int&gt;[39m[23m [3m[90m&lt;dbl&gt;[39m[23m ## [90m 1[39m 6 [4m1[24m001 20 ## [90m 2[39m 7 931 19 ## [90m 3[39m 8 980 20 ## [90m 4[39m 9 445 9 ## [90m 5[39m 10 484 10 ## [90m 6[39m 11 489 10 ## [90m 7[39m 12 246 5 ## [90m 8[39m 13 239 5 ## [90m 9[39m 14 90 2 ## [90m10[39m 15 95 2 Y consultando con las proyecciones de poblaci√≥n notamos que los ni√±os chicos est√°n sobrerepresentados en la muestra. Lo que nos hace considerar que debemos buscar una manera de ponderar nuestras observaciones para que reflejen a la poblaci√≥n. M√°s a√∫n, investigamos que algunas enfermedades est√°n asociadas a mayor prevalencia de anemia: paciente %&gt;% count(padecimiento) %&gt;% arrange(-n) ## [90m# A tibble: 7 x 2[39m ## padecimiento n ## [3m[90m&lt;chr&gt;[39m[23m [3m[90m&lt;int&gt;[39m[23m ## [90m1[39m infecci√≥n respiratoria 745 ## [90m2[39m mordedura de perro 723 ## [90m3[39m √∫lcera 723 ## [90m4[39m asma 713 ## [90m5[39m apendcitis 704 ## [90m6[39m picadura alacr√°n 701 ## [90m7[39m infecci√≥n intestinal 691 Utilizamos esta informaci√≥n para modelar y corregir nuestra estimaci√≥n original. Por ejemplo con modelos de regresi√≥n. Sin embargo, debemos preguntarnos: ¬øHay m√°s variables qu√© nos falta considerar? Nuestras estimaciones est√°n bien calibradas? Ejemplo: Polic√≠as y tr√°fico Supongamos que nos preguntan en cu√°nto reduce un polic√≠a el tr√°fico en un crucero grande de la ciudad. La cultura popular ha establecido que los polic√≠as en cruceros hacen m√°s tr√°fico porque no saben mover los sem√°foros. Nosotros decidimos buscar unos datos para entender esto. Escogemos entonces un grupo de cruceros problem√°ticos, registramos el tr√°fico cuando visitamos, y si hab√≠a un polic√≠a o no. Despu√©s de este esfuerzo, obtenemos los siguientes datos: ## [90m# A tibble: 10 x 2[39m ## [90m# Groups: policia [2][39m ## policia tiempo_espera_min ## [3m[90m&lt;int&gt;[39m[23m [3m[90m&lt;dbl&gt;[39m[23m ## [90m 1[39m 0 2.27 ## [90m 2[39m 0 2.65 ## [90m 3[39m 0 3.4 ## [90m 4[39m 0 0.39 ## [90m 5[39m 0 1.1 ## [90m 6[39m 1 10.8 ## [90m 7[39m 1 4.67 ## [90m 8[39m 1 7.77 ## [90m 9[39m 1 6.3 ## [90m10[39m 1 6.99 Lo que sabemos ahora es que la presencia de un polic√≠a es indicador de tr√°fico alto. El an√°lisis prosiguir√≠a calculando medias y medidas de error (escogimos una muestra aleatoria): ## `summarise()` ungrouping output (override with `.groups` argument) Si somos ingenuos, entonces podr√≠amos concluir que los polic√≠as efectivamente empeoran la situaci√≥n cuando manipulan los sem√°foros, y confirmar√≠amos la sabidur√≠a popular. Para juzgar este argumento desde el punto de vista causal, nos preguntamos primero: ¬øCu√°les son los contrafactuales (los contrafactuales explican que pasar√≠a si hubi√©ramos hecho otra cosa que la que efectivamente hicimos) de las observaciones? El estimador est√°ndar A la comparaci√≥n anterior - la diferencia de medias de tratados y no tratados - le llamamos usualmente el estimador est√°ndar del efecto causal. Muchas veces este es un estimador malo del efecto causal. En nuestro ejemplo, para llegar a la conclusi√≥n err√≥nea que confirma la sabidur√≠a popular, hicimos un supuesto importante: En nuestra muestra, los casos con polic√≠a act√∫an como contrafactuales de los casos sin polic√≠a. Asi que asumimos que los casos con polic√≠a y sin polic√≠a son similares, excepto por la existencia o no de polic√≠a. En nuestro ejemplo, quiz√° un analista m√°s astuto nota que tienen categor√≠as hist√≥ricas de qu√© tan complicado es cada crucero. Junta a sus datos, y obtiene: ## [90m# A tibble: 10 x 3[39m ## [90m# Groups: policia [2][39m ## policia tiempo_espera_min categoria ## [3m[90m&lt;int&gt;[39m[23m [3m[90m&lt;dbl&gt;[39m[23m [3m[90m&lt;fct&gt;[39m[23m ## [90m 1[39m 0 2.27 Fluido ## [90m 2[39m 0 2.65 Fluido ## [90m 3[39m 0 3.4 T√≠pico ## [90m 4[39m 0 0.39 Fluido ## [90m 5[39m 0 1.1 Fluido ## [90m 6[39m 1 10.8 Complicado ## [90m 7[39m 1 4.67 T√≠pico ## [90m 8[39m 1 7.77 Complicado ## [90m 9[39m 1 6.3 Complicado ## [90m10[39m 1 6.99 T√≠pico El analista argumenta entonces qu los polic√≠as se enviaron principalmente a cruceros que se consideran Complicados seg√∫n datos hist√≥ricos. Esto resta credibilidad a la comparaci√≥n que hicimos inicialmente: La comparaci√≥n del estimador est√°ndar no es de peras con peras: estamos comparando qu√© efecto tienen los polic√≠as en cruceros dif√≠ciles con cruceros no dif√≠ciles donde no hay polic√≠a. La raz√≥n de esto es que el proceso generador de los datos incluye el hecho de que no se env√≠an polic√≠as a lugares donde no hay tr√°fico. ¬øC√≥mo producir contrafactuales hacer la comparaci√≥n correcta? Experimentos tradicionales Idealmente, quisi√©ramos observar un mismo crucero en las dos condiciones: con y sin polic√≠as. Esto no es posible. En un experimento ‚Äútradicional‚Äù, como nos lo explicaron en la escuela, nos aproximamos a esto preparando dos condiciones id√©nticas, y luego alteramos cada una de ellas con nuestra intervenci√≥n. Si el experimento est√° bien hecho, esto nos da observaciones en pares, y cada quien tiene su contrafactual. La idea del experimiento tradicional es controlar todos los factores que intervienen en los resultados, y s√≥lo mover el tratamiento para producir los contrafactuales. M√°s en general, esta estrategia consiste en hacer bloques de condiciones, donde las condiciones son pr√°cticamente id√©nticas dentro e cada bloque. Comparamos entonces unidades tratadas y no tratadas dentro de cada bloque. Por ejemplo, si queremos saber si el tiempo de ca√≠da libre es diferente para un objeto m√°s pesado que otro, preparar√≠amos dos pesos con el mismo tama√±o pero de peso distinto. Soltar√≠amos los dos al mismo tiempo y comparar√≠amos el tiempo de ca√≠da de cada uno. En nuestro caso, como es usual en problemas de negocio o sociales, hacer esto es considerablemente m√°s dif√≠cil. No podemos ‚Äúpreparar‚Äù cruceros con condiciones id√©nticas. Sin embargo, podr√≠amos intentar bloquear los cruceros seg√∫n informaci√≥n que tenemos acerca de ellos, para hacer m√°s comparaciones e peras con peras. Bloqueo Podemos acercanos en lo posible a este ideal de experimentaci√≥n usando informaci√≥n existente. En lugar de hacer comparaciones directas entre unidades que recibieron el tratamiento y las que no (que pueden ser diferentes en otros aspectos, como vimos arriba), podemos refinar nuestras comparaciones bloqu√©andolas con variables conocidas. En el ejemplo de los polic√≠as, podemos hacer lo siguiente: dentro de cada categor√≠a de cruceros (fluido, t√≠pico o complicado), tomaremos una muestra de cruceros, algunos con polic√≠a y otros sin. Haremos comparaciones dentro de cada categor√≠a. Obtenemos un muestra con estas caracter√≠sticas (6 casos en cada categor√≠a de crucero, 3 con polic√≠a y 3 sin polic√≠a): categoria policia n Fluido 0 3 Fluido 1 3 T√≠pico 0 3 T√≠pico 1 3 Complicado 0 3 Complicado 1 3 Y ahora hacemos comparaciones dentro de cada bloque creado por categor√≠a: ## [90m# A tibble: 3 x 3[39m ## [90m# Groups: categoria [3][39m ## categoria `policia =0` `policia =1` ## [3m[90m&lt;fct&gt;[39m[23m [3m[90m&lt;dbl&gt;[39m[23m [3m[90m&lt;dbl&gt;[39m[23m ## [90m1[39m Fluido 2.1 0.8 ## [90m2[39m T√≠pico 5.6 4.2 ## [90m3[39m Complicado 10.4 8.6 Y empezamos a ver otra imagen en estos datos: comparando tipos e cruceros similares, los que tienen polic√≠a tienen tiempos de espera ligeramente m√°s cortos. ¬øHemos termniado? ¬øPodemos concluir que el efecto de un polic√≠a es beneficiosos pero considerablemente chico? ¬øQu√© problemas puede haber con este an√°lisis? Variables desconocidas El problema con el an√°lisis anterior es que controlamos por una variable que conocemos, pero muchas otras variables pueden estar ligadas con el proceso de selecci√≥n de cruceros para enviar polic√≠as. Por ejemplo, env√≠an o polic√≠as a cruceros T√≠picos solo cuando reportan mucho tr√°fico. No env√≠an a un pol√≠cia a un crucero Complicado si no presenta demasiado tr√°fico. Existen otras variables desconocidas que los tomadores de decisiones usan para enviar a los polic√≠as. En este caso, por ejemplo, los expertos hipot√©ticos nos se√±alan que hay algunos cruceros que aunque problem√°ticos a veces, su tr√°fico se resuelve r√°pidamente, mientras que otros tienen tr√°fico m√°s persistente, y prefieren enviar polic√≠as a los de tr√°fico persistente. La lista de cruceros persistentes est√°n en una hoja de excel que se comparte de manera informal. En resumen, no tenemos conocimiento detallado del proceso generador de datos en cuanto a c√≥mo se asignan los polic√≠as a los cruceros. Igual que en la secci√≥n anterior, podemos cortar esta complejidad usando aleatorizaci√≥n. N√≥tese que los expertos no est√°n haciendo nada malo: en su trabajo est√°n haciendo el mejor uso de los recursos que tienen. El problema es que por esa misma raz√≥n no podemos saber el resultado de sus esfuerzos, y si hay maneras de optimizar la asignaci√≥n que hacen actualmente. Aleatorizando el tratamiento Tomamos la decisi√≥n entonces de hacer un experimento que incluya aletorizaci√≥n. En un dia particular, escogeremos algunos cruceros. Dicidimos usar solamente cruceros de la categor√≠a Complicada y T√≠pica, pues esos son los m√°s interesantes para hacer intervenciones. Usaremos un poco de c√≥digo para entener el detalle: en estos datos, tenemos para cada caso los dos posibles resultados hipot√©ticos \\(y_0\\) y \\(y_1\\) (con policia y sin policia). En el experimento asignamos el tratamiento al azar: muestra_exp &lt;- trafico_tbl %&gt;% filter(categoria != &quot;Fluido&quot;) %&gt;% sample_n(200) %&gt;% # asignar tratamiento al azar, esta es nuestra intervenci√≥n: mutate(tratamiento_policia = rbernoulli(length(y_0), 0.5)) %&gt;% # observar resultado mutate(tiempo_espera_exp = ifelse(tratamiento_policia ==1, y_1, y_0)) N√≥tese la diferencia si tomamos la asignaci√≥n natural del tratamiento (polic√≠a o no): set.seed(134) muestra_natural &lt;- trafico_tbl %&gt;% filter(categoria != &quot;Fluido&quot;) %&gt;% sample_n(200) %&gt;% # usamos el tratamiento que se asign√≥ # policia indica si hubo o no polic√≠a en ese crucero # observar resultado mutate(tiempo_espera_obs = ifelse(policia ==1, y_1, y_0)) Resumimos nuestros resultados del experimento son: ## `summarise()` regrouping output by &#39;categoria&#39; (override with `.groups` argument) ## [90m# A tibble: 2 x 3[39m ## [90m# Groups: categoria [2][39m ## categoria `policia=0` `policia=1` ## [3m[90m&lt;fct&gt;[39m[23m [3m[90m&lt;dbl&gt;[39m[23m [3m[90m&lt;dbl&gt;[39m[23m ## [90m1[39m T√≠pico 6.24 4.97 ## [90m2[39m Complicado 15.8 8.47 Sin embargo, la muestra natural da: ## `summarise()` regrouping output by &#39;categoria&#39; (override with `.groups` argument) ## [90m# A tibble: 2 x 3[39m ## [90m# Groups: categoria [2][39m ## categoria `policia=0` `policia=1` ## [3m[90m&lt;fct&gt;[39m[23m [3m[90m&lt;dbl&gt;[39m[23m [3m[90m&lt;dbl&gt;[39m[23m ## [90m1[39m T√≠pico 5.49 4.35 ## [90m2[39m Complicado 10.8 8.93 ¬øCu√°l de los dos an√°lisis da la respuesta correcta a la pregunta: ayudan o no los polic√≠as a reducir el tr√°fico en los cruceros problem√°ticos? El experimento establece que un polic√≠a en promedio reduce a la mitad el tiempo de espera en un crucero complicado Resumen: selecci√≥n de unidades y tratamiento Vimos dos tipos de inferencia que requieren distintos dise√±os de estudio, en particual debemos considerar el mecanismo de aleatorizaci√≥n para entender las inferencias que podemos hacer: casual o a poblaciones. El punto crucial para entender las medidas de incertidumbre estad√≠stica es visualizar de manera hipot√©tica, replicaciones del estudio y las condiciones que llevaron a la selecci√≥n de la muestra. Esto es, entender el proceso generador de datos e imaginar replicarlo. Inferencia estad√≠stica de acuerdo al tipo del dise√±o (Ramsey and Schafer 2012). El cuadro arriba a la izquierda es donde el an√°lisis es m√°s simple y los resultados son m√°s f√°ciles de interpretar. Es posible hacer an√°lisis fuera de este cuadro, pero el proceso es m√°s complicado, requieren m√°s supuestos, conocimiento del dominio y habilidades de an√°lisis. En general resultan conclusiones menos s√≥lidas. Muchas veces no nos queda otra m√°s que trabajar fuera del cuadro ideal. Ubica los siguientes tipos de an√°lisis: Pruebas cl√≠nicas para medicinas Analizar c√≥mo afecta tener seguro m√©dico a los ingresos, usando datos del ENIGH. Estimaci√≥n de retorno sobre inversi√≥n en modelos de marketing mix. Asignaci√≥n natural del tratamiento Cuando consideramos un sistema donde se ‚Äúasignan‚Äù tratamientos, generalmente los tratamientos se asignan bajo un criterio de optimizaci√≥n o conveniencia. La cara buena de este hecho es que de alguna forma los resultados est√°n intentando optimizarse, y la gente est√° haciendo su trabajo. La cara mala de este hecho es que no podemos evaluar de manera simple la efectividad de los tratamientos. Y esto hace dif√≠cil optimizar de forma cuantificable los procesos, o entender qu√© funciona y qu√© no. Referencias "],
["pruebas-de-hip√≥tesis.html", "Secci√≥n 4 Pruebas de hip√≥tesis Comparaci√≥n con poblaciones de referencia Comparando distribuciones Permutaciones y el lineup Comparaciones con lineup 2 Prueba de permutaciones para proporciones Pruebas de hip√≥tesis tradicionales Tomadores de t√© 2 Pruebas de permutaci√≥n: Implementaci√≥n Ejemplo: tiempos de fusi√≥n Ejemplo: tiempos de fusi√≥n 2 Separaci√≥n de grupos La ‚Äúcrisis de replicabilidad‚Äù El jard√≠n de los senderos que se bifurcan Ejemplo: decisiones de an√°lisis y valores p Alternativas o soluciones", " Secci√≥n 4 Pruebas de hip√≥tesis Las primeras t√©cnicas inferenciales que veremos intentan contestar la siguiente pregunta: Si observamos cierto patr√≥n en los datos, ¬øc√≥mo podemos cuantificar la evidencia de que es un patr√≥n notable y no s√≥lo debido a fluctuaciones en los datos particulares que tenemos? ¬øC√≥mo sabemos que no estamos sobreinterpretando esas fluctuaciones? Por ejemplo: Un sistema tiene cierto comportamiento ‚Äúusual‚Äù para el cual tenemos datos hist√≥ricos. El sistema presenta fluctuaciones en el tiempo. Observamos la √∫ltima salida de nuestro sistema. Naturalmente, tiene fluctuaciones. ¬øEsas fluctuaciones son consistentes con la operaci√≥n usual del sistema? ¬øExiste evidencia para pensar que algo en el sistema cambi√≥? Comparaci√≥n con poblaciones de referencia En las prueba de hip√≥tesis, tratamos de construir distribuciones de referencia para comparar resultados que obtengamos con un ‚Äúest√°ndar‚Äù de variaci√≥n, y juzgar si nuestros resultados son consistentes con la referencia o no (Box, Hunter, and Hunter (1978)). En algunos casos, ese est√°ndar de variaci√≥n puede construirse con datos hist√≥ricos. Ejemplo Supongamos que estamos considerando cambios r√°pidos en una serie de tiempo de alta frecuencia. Hemos observado la serie en su estado ‚Äúnormal‚Äù durante un tiempo considerable, y cuando observamos nuevos datos quisi√©ramos juzgar si hay indicaciones o evidencia en contra de que el sistema sigue funcionando de manera similar. Digamos que monitoreamos ventanas de tiempo de tama√±o 20 y necesitamos tomar una decisi√≥n. Abajo mostramos cinco ejemplos donde el sistema opera normalmente, que muestra la variabilidad en el tiempo en ventanas cortas del sistema. Ahora suponemos que obtenemos una nueva ventana de datos. ¬øHay evidencia en contra de que el sistema sigue funcionando de manera similar? Nuestra primera inclinaci√≥n debe ser comparar: en este caso, compararamos ventanas hist√≥ricas con nuestra nueva serie: # usamos datos simulados para este ejemplo set.seed(8812) historicos &lt;- simular_serie(2000) ¬øVemos algo diferente en los datos nuevos (el panel de color diferente)? Indpendientemente de la respuesta, vemos que hacer este an√°lisis de manera tan simple no es siempre √∫til: seguramente podemos encontrar maneras en que la nueva muestra (4) es diferente a muestras hist√≥ricas. Por ejemplo, ninguna de muestras tiene un ‚Äúforma de monta√±a‚Äù tan clara. Nos preguntamos si no estamos sobreinterpretando variaciones que son parte normal del proceso. Podemos hacer un mejor an√°lisis si extraemos varias muestras del comportamiento usual del sistema, graficamos junto a la nueva muestra, y revolvemos las gr√°ficas para que no sepamos cu√°l es cu√°l. Entonces la pregunta es: ¬øPodemos detectar donde est√°n los datos nuevos? Esta se llama una prueba de lineup, o una prueba de ronda de sospechosos (Wickham et al. (2010)). En la siguiente gr√°fica, en uno de los p√°neles est√°n los datos recientemente observados. ¬øHay algo en los datos que distinga al patr√≥n nuevo? # nuevos datos obs &lt;- simular_serie(500, x_inicial = last(obs$obs)) # muestrear datos hist√≥ricos prueba_tbl &lt;- muestrear_ventanas(historicos, obs[1:20, ], n_ventana = 20) # gr√°fica de peque√±os m√∫ltiplos ggplot(prueba_tbl$lineup, aes(x = t_0, y = obs)) + geom_line() + facet_wrap(~rep, nrow = 4) + scale_y_log10() ¬øCu√°les son los datos nuevos (solo hay un panel con los nuevos datos)? ¬øQu√© implica que la gr√°fica que escogamos como ‚Äúm√°s diferente‚Äù no sean los datos nuevos? ¬øQu√© implica que le ‚Äúatinemos‚Äù a la gr√°fica de los datos nuevos? Ahora observamos al sistema en otro momento y repetimos la comparaci√≥n. En el siguiente caso obtenemos: Aunque es imposible estar seguros de que ha ocurrido un cambio, la diferencia de una de las series es muy considerable. Si identificamos los datos correctos, la probabilidad de que hayamos se√±alado la nueva serie ‚Äúsobreinterpretando‚Äù fluctuaciones en un proceso que sigue comport√°ndose normalente es 0.05 - relativamente baja. Detectar los datos diferentes es evidencia en contra de que el sistema sigue funcionando de la misma manera que antes. Observaciones y terminolog√≠a: Llamamos hip√≥tesis nula a la hip√≥tesis de que los nuevos datos son producidos bajo las mismas condiciones que los datos de control o de referencia. Si no escogemos la gr√°fica de los nuevos datos, nuestra conclusi√≥n es que la prueba no aporta evidencia en contra de la hip√≥tesis nula. Si escogemos la gr√°fica correcta, nuestra conclusi√≥n es que la prueba aporta evidencia en contra de la hip√≥tesis nula. ¬øQu√© tan fuerte es la evidencia, en caso de que descubrimos los datos no nulos? Cuando el n√∫mero de paneles es m√°s grande y detectamos los datos, la evidencia es m√°s alta en contra de la nula. Decimos que el nivel de significancia de la prueba es la probabilidad de seleccionar a los datos correctos cuando la hip√≥tesis nula es cierta (el sistema no ha cambiado). En el caso de 20 paneles, la significancia es de 1/20 = 0.05. Cuando detectamos los datos nuevos, niveles de significancia m√°s bajos implican m√°s evidencia en contra de la nula. Si acertamos, y la diferencia es m√°s notoria y fue muy f√°cil detectar la gr√°fica diferente (pues sus diferencias son m√°s extremas), esto tambi√©n sugiere m√°s evidencia en contra de la hip√≥tesis nula. Finalmente, esta prueba rara vez (o nunca) nos da seguridad completa acerca de ninguna conclusi√≥n, a√∫n cuando hici√©ramos muchos p√°neles. Comparando distribuciones Ahora intentamos un ejemplo m√°s t√≠pico. Supongamos tenemos muestras para tres grupos a, b y c, que quiere decir que dentro de cada grupo, el proceso e selecci√≥n de los elementos se hace de manera al azar y de manera sim√©trica (por ejemplo cada elemento tiene a misma probabiidad de ser seleccionado, y las extracciones se hacen de manera independiente.) Queremos comparar las distribuciones de los datos obtenidos para cada grupo. Quiz√° la pregunta detr√°s de esta comparaci√≥n es: el grupo de clientes b recibi√≥ una promoci√≥n especial. ¬øEst√°n gastando m√°s? La medici√≥n que comparamos es el gasto de los clientes. En la muestra observamos diferencias entre los grupos. Pero notamos adicionalmente que hay mucha variaci√≥n dentro de cada grupo. Nos podr√≠amos preguntar entonces si las diferencias que observamos se deben variaci√≥n muestral, por ejemplo. Podemos construir ahora una hip√≥tesis nula, que establece que las observaciones provienen de una poblaci√≥n similar: Las tres poblaciones (a, b, c) son pr√°cticamente indistiguibles. En este caso, la variaci√≥n que observamos se deber√≠a a que tenemos informaci√≥n incompleta. Como en el ejemplo anterior necesitamos construir o obtener una distribuci√≥n de referencia para comparar qu√© tan extremos o diferentes son los datos que observamos. Esa distribuci√≥n de referencia deber√≠a estar basada en el supuesto de que los grupos producen datos de distribuciones similares. Si tuvieramos mediciones similares hist√≥ricas de estos tres grupos, quiz√° podr√≠amos extraer datos de referencia y comparar, como hicimos en el ejempo anterior. Pero esto es menos com√∫n en este tipo de ejemplos. Permutaciones y el lineup Para abordar este problema podemos pensar en usar permutaciones de los grupos de la siguiente forma (Box, Hunter, and Hunter (1978), Hesterberg (2014)): Si los grupos producen datos bajo procesos id√©nticos, entonces los grupos a, b, c solo son etiquetas que no contienen informaci√≥n. Podr√≠amos permutar al azar las etiquetas y observar nuevamente la gr√°fica de caja y brazos por grupos. Si la hip√≥tesis nula es cierta (grupos id√©nticos), esta es una muestra tan veros√≠mil como la que obtuvimos. As√≠ que podemos construir datos de referencia permutando las etiquetas de los grupos al azar, y observando la variaci√≥n que ocurre. Si la hip√≥tesis nula es cercana a ser cierta, no deber√≠amos de poder distinguir f√°cilmente los datos observados de los producidos con las permutaciones al azar. Vamos a intentar esto, por ejemplo usando una gr√°fica de cuantiles simplificada. Hacemos un lineup, o una rueda de sospechosos (usamos el paquete Wickham et al. (2018), ver Wickham et al. (2010)), donde 19 de los acusados son generados mediante permutaciones al azar de la variable del grupo, y el culpable (los verdaderos datos) est√°n en una posici√≥n escogida al azar. ¬øPodemos identificar los datos verdaderos? Para evitar sesgarnos, tambi√©n ocultamos la etiqueta verdadera Usamos una gr√°fica que muestra los cuantes 0.10, 0.50, 0.90: set.seed(88) reps &lt;- lineup(null_permute(&quot;grupo&quot;), muestra_tab, n = 20) reps_mezcla &lt;- reps %&gt;% mutate(grupo_1 = factor(digest::digest2int(grupo) %% 177)) grafica_cuantiles(reps_mezcla, grupo_1, x) + facet_wrap(~.sample, ncol = 5) + ylab(&quot;x&quot;) + labs(caption = &quot;Mediana y percentiles 10% y 90%&quot;)+ geom_point(aes(colour = grupo_1)) Y la pregunta que hacemos es podemos distinguir nuestra muestra entre todas las replicaciones producidas con permutaciones? ¬øD√≥nde est√°n los datos observados? Seg√∫n tu elecci√≥n, ¬øqu√© tan diferentes son los datos observados de los datos nulos? En este ejemplo, es dif√≠cil indicar cu√°les son los datos. Los grupos tienen distribuciones similares y es factible que las diferencias que observamos se deban a variaci√≥n muestral. Si la persona escoge los verdaderos datos, encontramos evidencia en contra de la hip√≥tesis nula (los tres grupos son equivalentes). En algunos contextos, se dice que los datos son significativamente diferentes al nivel 0.05. Esto es evidencia en contra de que los datos se producen de manera homog√©nea, independientemente del grupo. Si la persona escoge uno de los datos permutados, no encontramos evidencia en contra de que los tres grupos producen datos con distribuciones similares. Comparaciones con lineup 2 Repitimos el ejemplo para otra muestra (en este ejemplo el proceso generador de datos es diferente para el grupo b): Hacemos primero la prueba del lineup: set.seed(121) reps &lt;- lineup(null_permute(&quot;grupo&quot;), muestra_tab, n = 20) grafica_cuantiles(reps %&gt;% mutate(grupo_escondido = factor(digest::digest2int(grupo) %% 177)), grupo_escondido, x) + facet_wrap(~.sample) + ylab(&quot;x&quot;) + coord_flip() + geom_point(aes(colour = grupo_escondido)) Podemos distinguir m√°s o menos claramente que est√° localizada en valores m√°s altos y tiene mayor dispersi√≥n. En este caso, como en general podemos identificar los datos, obtenemos evidencia en contra de que los tres grupos tienen distribuciones iguales. Estos ejemplos siguen la idea de inferencia visual propuestas en Wickham et al. (2010), Cook et al. (2012) e implementadas en R en el paquete lineup. Son pruebas muy flexibles y estad√≠sticamente rigurosas. Prueba de permutaciones para proporciones Veremos otro ejemplo donde podemos hacer m√°s concreta la idea de distribuci√≥n nula o de referencia usando pruebas de permutaciones. Supongamos que con nuestra muestra de tomadores de t√©, queremos probar la siguiente hip√≥tesis nula: Los tomadores de t√© en bolsas exclusivamente usan az√∫car m√°s a tasas simillares que los tomadores de t√© suelto (que pueden o no tambi√©n tomar t√© en bolsita). Los datos que obtuvimos en nuestra encuesta, en conteos, son: te_azucar &lt;- tea %&gt;% select(how, sugar) %&gt;% mutate(how = ifelse(how == &quot;tea bag&quot;, &quot;bolsa_exclusivo&quot;, &quot;suelto o bolsa&quot;)) te_azucar %&gt;% count(how, sugar) %&gt;% pivot_wider(names_from = how, values_from = n) %&gt;% formatear_tabla() sugar bolsa_exclusivo suelto o bolsa No.sugar 81 74 sugar 89 56 Y en proporciones tenemos que: how prop_azucar n bolsa_exclusivo 0.52 170 suelto o bolsa 0.43 130 Pero distintas muestras podr√≠an haber dado distintos resultados. Nos preguntamos qu√© tan fuerte es la evidencia en contra de que en realidad los dos grupos de personas usan az√∫car en proporciones similares, y la diferencia que vemos se puede atribuir a variaci√≥n muestral. En este ejemplo, podemos usar una estad√≠stica de prueba num√©rica, por ejemplo, la diferencia entre las dos proporciones: \\[p_1 - p_2\\]. (tomadores de en bolsa solamente vs. suelto y bolsa). El proceso ser√≠a entonces: La hip√≥tesis nula es que los dos grupos tienen distribuciones iguales, que este caso quiere decir que en la poblaci√≥n, tomadores de t√© solo en bolsa usan az√∫car a las mismas tasas que tomadores de suelto o bolsas. Bajo nuestra hip√≥tesis nula (proporciones iguales), producimos una cantidad grande (por ejemplo 10 mil o m√°s) de muestras permutando las etiquetas de los grupos. Evaluamos nuestra estad√≠stica de prueba en cada una de las muestras permutadas. El conjunto de valores obtenidos nos da nuestra distribuci√≥n de referencia (ya no estamos limitados a 20 replicaciones como en las pruebas gr√°ficas). Y la pregunta clave es: ¬øel valor de la estad√≠stica en nuestra muestra es extrema en comparaci√≥n a la distribuci√≥n de referencia? # ESta funci√≥n calcula la diferencia entre grupos de inter√©s calc_diferencia &lt;- function(datos){ datos %&gt;% mutate(usa_azucar = as.numeric(sugar == &quot;sugar&quot;)) %&gt;% group_by(how) %&gt;% summarise(prop_azucar = mean(usa_azucar)) %&gt;% pivot_wider(names_from = how, values_from = prop_azucar) %&gt;% mutate(diferencia_prop = bolsa_exclusivo - `suelto o bolsa`) %&gt;% pull(diferencia_prop) } # esta funci√≥n hace permutaciones y calcula la diferencia para cada una permutaciones_est &lt;- function(datos, variable, calc_diferencia, n = 1000){ # calcular estad√≠stica para cada grupo permutar &lt;- function(variable){ sample(variable, length(variable)) } tbl_perms &lt;- tibble(.sample = seq(1, n-1, 1)) %&gt;% mutate(diferencia = map_dbl(.sample, ~ datos %&gt;% mutate({{variable}}:= permutar({{variable}})) %&gt;% calc_diferencia)) bind_rows(tbl_perms, tibble(.sample = n, diferencia = calc_diferencia(datos))) } La diferencia observada es: dif_obs &lt;- calc_diferencia(te_azucar) dif_obs %&gt;% round(3) ## [1] 0.093 Ahora construimos nuestra distribuci√≥n nula o de referencia: valores_ref &lt;- permutaciones_est(te_azucar, how, calc_diferencia, n = 10000) reps &lt;- lineup(null_permute(&quot;how&quot;), te_azucar, n = 10000) valores_ref &lt;- reps %&gt;% group_by(.sample) %&gt;% nest() %&gt;% mutate(diferencia = lapply(data, calc_diferencia)) %&gt;% unnest(diferencia) Y graficamos nuestros resultados (con un histograma y una gr√°fica de cuantiles, por ejemplo). la estad√≠stica evaluada un cada una de nuestras muestras permutadas: g_1 &lt;- ggplot(valores_ref, aes(sample = diferencia)) + geom_qq(distribution = stats::qunif) + xlab(&quot;f&quot;) + ylab(&quot;diferencia&quot;) + labs(subtitle = &quot;Distribuci√≥n nula o de referencia&quot;) g_2 &lt;- ggplot(valores_ref, aes(x = diferencia)) + geom_histogram(binwidth = 0.04) + coord_flip() + xlab(&quot;&quot;) + labs(subtitle = &quot; &quot;) g_1 + g_2 Este es el rango de fluctuaci√≥n usual para nuestra estad√≠stica *bajo la hip√≥tesis de que los dos grupos de tomadores de t√© consumen t√© a la misma tasa. El valor que obtuvimos en nuestros datos es 0.09, que no es un valor extremo en la distribuci√≥n de referencia que vimos arriba: esta muestra no aporta mucha evidencia en contra de que los grupos tienen distribuciones similares. Podemos graficar otra vez marcando el valor de referencia: # Funci√≥n de distribuci√≥n acumulada (inverso de funci√≥n de cuantiles) dist_perm &lt;- ecdf(valores_ref$diferencia) # Calculamos el percentil del valor observado percentil_obs &lt;- dist_perm(dif_obs) g_1 &lt;- ggplot(valores_ref, aes(sample = diferencia)) + geom_qq(distribution = stats::qunif) + xlab(&quot;f&quot;) + ylab(&quot;diferencia&quot;) + labs(subtitle = &quot;Distribuci√≥n nula o de referencia&quot;) + geom_hline(yintercept = dif_obs, colour = &quot;red&quot;) + annotate(&quot;text&quot;, x = 0.3, y = dif_obs - 0.05, label = &quot;diferencia observada&quot;, colour = &quot;red&quot;) g_2 &lt;- ggplot(valores_ref, aes(x = diferencia)) + geom_histogram(binwidth = 0.04) + coord_flip() + xlab(&quot;&quot;) + labs(subtitle = &quot; &quot;) + geom_vline(xintercept = dif_obs, colour = &quot;red&quot;) + annotate(&quot;text&quot;, x = dif_obs, y = 2000, label = percentil_obs,vjust = -0.2, colour = &quot;red&quot;) g_1 + g_2 Y vemos que es un valor algo (pero no muy) extremo en la distribuci√≥n de referencia que vimos arriba: esta muestra no aporta una gran cantidad de evidencia en contra de que los grupos tienen distribuciones similares, que en este caso significa que los dos grupos usan az√∫car a tasas similares. Pruebas de hip√≥tesis tradicionales Comencemos recordando la definici√≥n de par√°metro y estad√≠stica. Definici√≥n. Un par√°metro es una caracter√≠stica (num√©rica) de una poblaci√≥n o de una distribuci√≥n de probabilidad. Una estad√≠stica es una caracter√≠stica (num√©rica) de los datos. Cualquier funci√≥n de un par√°metro es tambi√©n un par√°metro, y cualquier funci√≥n de una estad√≠stica es tambi√©n una estad√≠stica. Cuando la estad√≠stica se calcula de una muestra aleatoria, es por consiguiente aleatoria y es por tanto una variable aleatoria. Por ejemplo \\(\\mu\\) y \\(\\sigma\\) son par√°metros de la distribuci√≥n normal con funci√≥n de densidad \\(f(x) = (1/\\sqrt{2\\pi}\\sigma)e^{(x-\\mu)^2/(2\\sigma^2)}\\). La varianza \\(\\sigma^2\\), y el cociente (se√±al a ruido) \\(\\mu/\\sigma\\) tambi√©n son par√°metros. Si \\(X_1,X_2,...,X_n\\) son una muestra aleatoria, entinces la media \\(\\bar{X}=1/n\\sum X_i\\) es una estad√≠stica. Ahora podemos pasar a las definiciones correspondientes a pruebas de hip√≥tesis (o pruebas de significancia). Definici√≥n. Denotamos por \\(H_0\\) a la hip√≥tesis nula la cual usualmente tratamos como la afirmaci√≥n del status quo. La hip√≥tesis alternativa la denotamos por \\(H_1\\) y representa el supuesto que est√° a prueba y para el cual buscamos evidencia en los datos. Definici√≥n. La hip√≥tesis normalmente se plantea en t√©rminos de un par√°metro (\\(\\theta\\in\\mathbb{R}\\)) o conjunto de par√°metros (\\(\\theta\\in\\mathbb{R}^p\\)) de la distribuci√≥n de inter√©s (por ejemplo media, moda, varianza). Para una hip√≥tesis nula del estilo \\(H_0: \\theta = \\theta_0,\\) la hip√≥tesis a contrastar se puede denominar como: Hip√≥tesis alternativa de una cola \\(H_1: \\theta &amp;gt; \\theta_0\\) Hip√≥tesis alternativa de dos colas \\(H_1: \\theta \\neq \\theta_0\\) En el ejemplo anterior planteamos hip√≥tesis nula (proporciones iguales) e hip√≥tesis alternativa que la proporci√≥n de tomadores de te suelto que usan az√∫car en menor, esto corresponde a una hip√≥tesis alternativa a dos colas: \\(H_0: p_1 = p_2\\), y \\(H_1:p_1 &gt; p_2\\). Definici√≥n. Una estad√≠stica de prueba es una funci√≥n num√©rica de los datos cuyo valor determina el resultado de la prueba. La funci√≥n usualmente es denotada por \\(T(\\bf X)\\) donde \\(\\bf X\\) representa los datos como variable aleatoria. Por ejemplo, \\(T = T(X_1, \\ldots, X_N)\\) si s√≥lo tenemos una muestra, o por \\(T = T(X_1, \\ldots, X_N, Y_1, \\ldots, Y_M)\\) en el caso de tener dos muestras. Al evaluar la prueba para un conjunto de datos dado, \\(x\\), √©sta se denomina estad√≠stica de prueba observada, \\(t = T(x).\\) La estad√≠stica de prueba correspondiente al ejemplo es \\(T = p_1 - p_2\\) Definici√≥n. El valor p es la probabilidad de que bajo la hip√≥tesis nula los datos generen un valor tan extremo como la estad√≠stica de prueba observada. Por ejemplo, si consideramos la hip√≥tesis nula admite valores grandes, el valor p se calcula como \\(P(T \\geq t).\\) En el ejemplo de tomadores de t√© lo calculamos usando el percentil donde nuestra observaci√≥n cae en la distribuci√≥n generada por las permutaci√≥n (valor p de una cola). . Podemos calcular, por ejemplo: Valor p de dos colas: Si la hip√≥tesis nula es cierta, ¬øcu√°l es la probabilidad de observar una diferencia tan extrema o m√°s extrema de lo que observamos? Considerando en este caso interpretamos extrema como que cae lejos de donde a mayor√≠a de la distribuci√≥n se concentra, podemos calcular el valor p como sigue. A partir de el valor observado, consideramos cu√°l dato es menor: la probabilidad bajo lo hip√≥tesis nula de observar una diferencia mayor de a que observamos, o la probabilidad de observar una diferencia menor a la que observamos. Tomamos el m√≠nimo y multiplicamos por dos (Hesterberg (2014)): 2 * min(dist_perm(dif_obs), (1 - dist_perm(dif_obs))) ## [1] 0.085 Este valor p se considera como evidencia ‚Äúmoderada‚Äù en contra de la hip√≥tesis nula. Valores p m√°s chicos (observaciones m√°s extremas en comparaci√≥n con la referencia) aportan m√°s evidencia en contra de la hip√≥tesis de que los grupos de tomadores de t√© , y valores m√°s grandes aportan menos evidencia. Definici√≥n. Un resultado es estadisticamente significativo si tiene muy baja probabilidad de suceder al azar. Entre m√°s peque√±o requiramos un valor p oara declarar un resultado estad√≠sticamente significativo, somos m√°s conservadores. Las pruebas de hip√≥tesis con frecuencia inician contestando una pregunta m√°s general que los valores p: ¬øCu√°l es la distribuci√≥n de la estad√≠stica de prueba cuando no hay efecto real? Definici√≥n. La distribuci√≥n nula es la disttibuci√≥n de la estad√≠stica de prueba si la hip√≥tesis nula es cierta. En ocasiones tambi√©n nos referimos a ella como la distribuci√≥n de referencia pues estamos comparando la estad√≠stica de prueba observada a su referencia para determinar que tan inusual es. En el ejemplo de tomadores de te aproximamos la distribuci√≥n nula (y los valores p) con simulaci√≥n; sin embargo, para algunas estadisticas hay m√©todos exactos. En particular, usamos el m√©todo de pruebas de permutaci√≥n, el algoritmo para dos grupos ser√≠a como sigue. Prueba de permutaci√≥n para dos muestras Supongamos que tenemos m observaciones de una poblaci√≥n y n de otra. Combina los m+n valores. Repite: Saca una remuestra de tama√±o m sin reemplazo. Usa las n observaciones restantes para obtener la otra muestra. Calcula la estad√≠stica de prueba (que compara las muestras). Calcula el valor p como la fracci√≥n de las veces que la estad√≠stica sobrepas√≥ la estad√≠stica observada, multiplica por 2 para una prueba de dos lados. La distribuci√≥n de la estad√≠stica a lo largo de las remuestras de permutaci√≥n es la distribuci√≥n de permutaci√≥n. √âsta puede ser exacta, si se calcula exhaustivamente (cuando tenemos pocas observaciones es posible) o aproximada. Tomadores de t√© 2 Ahora hacemos una prueba de permutaciones otro par de proporciones con el mismo m√©todo. La hip√≥tesis nula ahora es: Los tomadores de t√© Earl Gray usan az√∫car a una tasa similar a los tomadores de t√© negro Los datos que obtuvimos en nuestra encuesta, en conteos, son: sugar black Earl Grey No.sugar 51 84 sugar 23 109 Y en porcentajes tenemos que: prop_azucar &lt;- te_azucar %&gt;% count(Tea, sugar) %&gt;% group_by(Tea) %&gt;% mutate(prop = 100 * n / sum(n), n = sum(n)) %&gt;% filter(sugar == &quot;sugar&quot;) %&gt;% select(Tea, prop_azucar = prop, n) %&gt;% mutate(&#39;% usa az√∫car&#39; = round(prop_azucar)) %&gt;% select(-prop_azucar) prop_azucar %&gt;% formatear_tabla Tea n % usa az√∫car black 74 31 Earl Grey 193 56 Pero distintas muestras podr√≠an haber dado distintos resultados. Nos preguntamos que tan fuerte es la evidencia en contra de que en realidad los dos grupos de personas usan az√∫car en proporciones similares, y la diferencia que vemos se puede atribuir a variaci√≥n muestral. Escribimos la funci√≥n que calcula diferencias para cada muestra: calc_diferencia_2 &lt;- function(datos){ datos %&gt;% mutate(usa_azucar = as.numeric(sugar == &quot;sugar&quot;)) %&gt;% group_by(Tea) %&gt;% summarise(prop_azucar = mean(usa_azucar)) %&gt;% pivot_wider(names_from = Tea, values_from = prop_azucar) %&gt;% mutate(diferencia_prop = `Earl Grey` - black) %&gt;% pull(diferencia_prop) } La diferencia observada es: ## [1] 0.254 Ahora construimos nuestra distribuci√≥n nula o de referencia: set.seed(2) reps &lt;- lineup(null_permute(&quot;Tea&quot;), te_azucar, n = 10000) valores_ref &lt;- reps %&gt;% group_by(.sample) %&gt;% nest() %&gt;% mutate(diferencia = lapply(data, calc_diferencia_2)) %&gt;% unnest(diferencia) Y podemos graficar la distribuci√≥n de referencia otra vez marcando el valor observado En este caso, la evidencia es muy fuerte en contra de la hip√≥tesis nula, pues el resultado que obtuvimos es muy extremo en relaci√≥n a la distribuci√≥n de referencia. El valor p es cercano a 0. Haz una prueba de permutaciones para diferencia de medias para comparar la propina en cena vs en comidas. * Grafica la distribuci√≥n de referencia. * Calcula el valor p (dos colas). Pruebas de permutaci√≥n: Implementaci√≥n Hasta ahora nos hemos centrado en ejemplos de diferencias en medias. Podemos extender las pruebas de permutaci√≥n a \\(\\bar{X}\\) (la media de la primera muestra), \\(m\\bar{X}\\) (la suma de las observaciones en la primera muestra), y m√°s. Teorema. En pruebas de permutaci√≥n, si dos estad√≠sticas de prueba \\(T_1\\) y \\(T_2\\) est√°n relacionadas por una funci√≥n estr√≠ctamente creciente, \\(T_1(X^*)=f(T_2(X^*))\\) donde \\(X^*\\) es una remuestra de permutaci√≥n de los datos originales, entonces los valores p ser√°n los mismos en las pruebas de permutaci√≥n. Agregar uno al numerador y denominador. Cuando se calcula el valor p en la implementaci√≥n de muestreo, agregar uno al numerador y denominador. Esto corresponde a incluir los datos como una remuestra adicional y sirve para evitar reportar el valor p \\(0\\) que es imposible pues siempre hay una remuestra con un valor al menos tan extremo como los datos observados (los datos mismos). Muestras con reemplazo de la Distribuci√≥n Nula. En la implementaci√≥n de muestreo, no nos aseguramos que las remuestras sean √∫nicas. Ser√≠a m√°s acertado tomar muestras sin reemplazo, sin embargo, el costo computacional es demasiado alto. Entre m√°s muestras m√°s exactitud. Hemos usado 10,000 muestras, en general entre m√°s remuestras tendremos una mejor estimaci√≥n del valor p. Si el verdadero valor es \\(p\\) el estimado tendr√° una varianza aproximadamente de \\(p(1-p)/N\\) donde \\(N\\) es el n√∫mero de remuestras. Observaci√≥n. As√≠ como los \\(n\\) datos originales son una muestra de la poblaci√≥n, tambi√©n las \\(N\\) remuestras de la estad√≠stica son una muestra de una poblaci√≥n, en este caso de la distribuci√≥n nula. La pruebas de permutaciones son m√°s √∫tiles cuando nuestra hip√≥tesis nula se refiere que la distribuci√≥n de los grupos son muy similares, o la independencia entre observaciones y grupo. Esto tambi√©n aplica cuando queremos probar por ejemplo, que una variable num√©rica Y es independiente de X. Hay algunas hip√≥tesis que no se pueden probar con este m√©todo, como por ejemplo, las que se refieren a una sola muestra: ¬ølos datos son consistentes con que su media es igual a 5? Adicionalmente, en algunas ocasiones queremos probar aspectos m√°s espec√≠ficos de las diferencias: como ¬øson iguales las medias o medianas de dos grupos de datos? ¬øTienen dispersi√≥n similar? Las pruebas de permutaciones no est√°n tan perfectamente adaptadas a este problema, pues prueban todos los aspectos de las distribuciones que se comparan, a√∫n cuando escogamos una estad√≠stica particular que pretende medir, por ejemplo, diferencia de medias. Eso quiere decir que podemos rechazar igualdad de medias, por ejemplo, cuando en realidad otra caracter√≠stica de las distribuciones es la que difiere mucho en las poblaciones En algunas referencias (ver (???), (???)) se argumenta que de todas formas las pruebas de permutaciones son relativamente robustas a esta desadaptaci√≥n. Un caso excepcional, por ejemplo, es cuando las poblaciones que comparamos resultan tener dispersi√≥n extremadamente distinta, y adicionalmente los tama√±os de muestra de los grupos son muy desiguales (otra vez, ver ejemplos en (???)). Ejemplo: tiempos de fusi√≥n Veamos el siguiente ejemplo, que es un experimento donde se midi√≥ el tiempo que tardan distintas personas en fusionar un estereograma para ver una imagen 3D. (Cleveland (1993)). Existen dos condiciones: en una se dio indicaciones de qu√© figura ten√≠an que buscar (VV) y en otra no se dio esa indicaci√≥n. ¬øLas instrucciones verbales ayudan a fusionar m√°s r√°pido el estereograma? Una pregunta que podr√≠amos hacer es: considerando que hay mucha variaci√≥n en el tiempo de fusi√≥n dentro de cada tratamiento, necesitamos calificar la evidencia de nuestra conclusi√≥n (el tiempo de fusi√≥n se reduce con informaci√≥n verbal). Podemos usar una prueba de permutaciones, esta vez justific√°ndola por el hecho de que los tratamientos se asignan al azar: si los tratamientos son indistinguibles, entonces las etiquetas de los grupos son solo etiquetas, y permutarlas dar√≠a muestras igualmente veros√≠miles. En este caso, compararemos gr√°ficas de cuantiles de los datos con los producidos por permutaciones (transformamos los datos pues en este caso es m√°s apropiado una comparaci√≥n multiplicativa): ¬øPodemos identificar los datos? En general, muy frecuentemente las personas identifican los datos correctamente, lo que muestra evidencia considerable de que la instrucci√≥n verbal altera los tiempos de respuesta de los partipantes, y en este caso ayuda a reducir el tiempo de fusi√≥n de los estereogramas. Ejemplo: tiempos de fusi√≥n 2 Podemos usar las pruebas de permutaciones para distintos de tipos de estad√≠sticas: medianas, medias, comparar dispersi√≥n usando rangos intercuartiles o varianzas, etc. Regresamos a los tiempos de fusi√≥n. Podemos hacer una prueba de permutaciones para la diferencia de las medias o medianas, por ejemplo. En este ejemplo usaremos una medida de centralidad un poco diferente, como ilustraci√≥n: el promedio de los cuartiles superior e inferior de las dos distribuciones. Usaremos el cociente de estas dos cantidades para medir su diferencia stat_fusion &lt;- function(x){ (quantile(x, 0.75) + quantile(x, 0.25))/2 } calc_fusion &lt;- function(stat_fusion){ fun &lt;- function(datos){ datos %&gt;% group_by(nv.vv) %&gt;% summarise(est = stat_fusion(time)) %&gt;% pivot_wider(names_from = nv.vv, values_from = est) %&gt;% mutate(dif = VV / NV ) %&gt;% pull(dif) } fun } calc_cociente &lt;- calc_fusion(stat_fusion) dif_obs &lt;- calc_cociente(fusion) # permutar valores_ref &lt;- permutaciones_est(fusion, nv.vv, calc_cociente, n = 10000) dist_perm_nv &lt;- ecdf(valores_ref$diferencia) cuantil_obs &lt;- dist_perm_nv(dif_obs) Y el valor p de dos colas es dist_perm_nv &lt;- ecdf(valores_ref$diferencia) 2 * min(dist_perm_nv(dif_obs), 1 - dist_perm_nv(dif_obs)) ## [1] 0.0354 Lo que muestra evidencia considerable, aunque no muy fuerte, de que la instrucci√≥n verbal ayuda a reducir el tiempo de fusi√≥n de los estereogramas: la caja del diagrama de caja y brazos para el grupo VV est√° encogida por un factor menor a 1. Separaci√≥n de grupos Este ejemplo tomado de Roy Chowdhury et al. (2014) (tanto la idea como el c√≥digo). La pregunta que se aborda en ese estudio es: Existen m√©todos de clasificaci√≥n (supervisados o no supervisados) para formar grupos en t√©rminos de variables que describen a los individuos Estos m√©todos (an√°lisis discriminante, o k-means, por ejemplo), pretenden formar grupos compactos, bien separados entre ellos. Cuando aplicamos el m√©todo, obtenemos clasificadores basados en las variables de entrada. La pregunta es: ¬ølos grupos resultantes son producto de patrones que se generalizan a la poblaci√≥n, o capitalizaron en variaci√≥n aleatoria para formarse? Especialmente cuando tenemos muchas mediciones de los individuos, y una muestra relativamente chica, Es relativamente f√°cil encontrar combinaciones de variables que separan los grupos, aunque estas combinaciones y diferencias est√°n basadas en ruido y no generalizan a la poblaci√≥n. Como muestran en Roy Chowdhury et al. (2014), el lineup es √∫til para juzgar si tenemos evidencia en contra de que los grupos en realidad son iguales, y usamos variaci√≥n muestral para separarlos. Avispas (opcional) En el siguiente ejemplo, tenemos 4 grupos de avispas (50 individuos en total), y para cada individuo se miden expresiones de 42 genes distintos. La pregunta es: ¬øPodemos separar a los grupos de avispas dependiendo de sus mediciones? En este se us√≥ an√°lisis discriminante para buscar proyecciones de los datos en dimensi√≥n baja de forma que los grupos sean lo m√°s compactos y separados posibles. Para probar qu√© tan bien funciona este m√©todo, podemos hacer una prueba de permutaci√≥n, aplicamos LDA y observamos los resultados. Y vemos que incluso permutando los grupos, es generalmente posible separarlos en grupos bien definidos: la b√∫squeda es suficientemente agresiva para encontrar combinaciones lineales que los separan. Que no podamos distinguir los datos verdaderos de las replicaciones nulas indica que este m√©todo dif√≠cilmente puede servir para separar los grupos claramente. Otro enfoque ser√≠a separar los datos en una muestra de entrenamiento y una de prueba (que discutiremos en la √∫ltima sesi√≥n). Aplicamos el procedimiento a la muestra de entrenamiento y luego vemos qu√© pasa con los datos de prueba: set.seed(8) wasps_1 &lt;- wasps %&gt;% mutate(u = runif(nrow(wasps), 0, 1)) wasps_entrena &lt;- wasps_1 %&gt;% filter(u &lt;= 0.8) wasps_prueba &lt;- wasps_1 %&gt;% filter(u &gt; 0.8) wasp.lda &lt;- MASS::lda(Group ~ ., data=wasps_entrena[,-1]) wasp_ld_entrena &lt;- predict(wasp.lda, dimen=2)$x %&gt;% as_tibble(.name_repair = &quot;universal&quot;) %&gt;% mutate(tipo = &quot;entrenamiento&quot;) %&gt;% mutate(grupo = wasps_entrena$Group) wasp_ld_prueba &lt;- predict(wasp.lda, newdata = wasps_prueba, dimen=2)$x %&gt;% as_tibble(.name_repair = &quot;universal&quot;) %&gt;% mutate(tipo = &quot;prueba&quot;)%&gt;% mutate(grupo = wasps_prueba$Group) wasp_lda &lt;- bind_rows(wasp_ld_entrena, wasp_ld_prueba) ggplot(wasp_lda, aes(x = LD1, y = LD2, colour = grupo)) + geom_point(size = 3) + facet_wrap(~tipo) Aunque esta separaci√≥n de datos es menos efectiva en este ejemplo por la muestra chica, podemos ver que la separaci√≥n lograda en los datos de entrenamiento probablemente se debe a variaci√≥n muestral. La ‚Äúcrisis de replicabilidad‚Äù Recientemente (Ioannidis (2005)) se ha reconocido en campos como la sicolog√≠a la crisis de replicabilidad. Varios estudios que recibieron mucha publicidad inicialmente no han podido ser replicados posteriormente por otros investigadores. Por ejemplo: Hacer poses poderosas produce cambios fisiol√≥gicos que mejoran nuestro desempe√±o en ciertas tareas Mostrar palabras relacionadas con ‚Äúviejo‚Äù hacen que las personas caminen m√°s lento (efectos de priming) En todos estos casos, el argumento de la evidencia de estos efectos fue respaldada por una prueba de hip√≥tesis nula con un valor p menor a 0.05. La raz√≥n es que ese es el est√°ndar de publicaci√≥n seguido por varias √°reas y revistas. La tasa de no replicabilidad parece ser mucho m√°s alta (al menos la mitad o m√°s seg√∫n algunas fuentes, como la se√±alada arriba) que lo sugerir√≠a la tasa de falsos positivos (menos de 5%) Este problema de replicabilidad parece ser m√°s frecuente cuando: Se trata de estudios de potencia baja: mediciones ruidosas y tama√±os de muestra chicos. El plan de an√°lisis no est√° claramente definido desde un principio (lo cual es dif√≠cil cuando se est√°n investigando ‚Äúfen√≥menos no estudiados antes‚Äù) ¬øA qu√© se atribuye esta crisis de replicabilidad? El jard√≠n de los senderos que se bifurcan Aunque haya algunos ejemplos de manipulaciones conscientes ‚Äìe incluso, en menos casos, malintencionadas‚Äì para obtener resultados publicables o significativos (p-hacking), como vimos en ejemplos anteriores, hay varias decisiones, todas razonables, que podemos tomar cuando estamos buscando las comparaciones correctas. Algunas pueden ser: Transformar los datos (tomar o no logaritmos, u otra transformaci√≥n) Editar datos at√≠picos (razonable si los equipos pueden fallar, o hay errores de captura, por ejemplo) Distintas maneras de interpretar los criterios de inclusi√≥n de un estudio (por ejemplo, algunos participantes mostraron tener gripa, o revelaron que durmieron muy poco la noche anterior, etc. ¬ølos dejamos o los quitamos?) Dado un conjunto de datos, las justificaciones de las decisiones que se toman en cada paso son razonables, pero con datos distintos las decisiones podr√≠an ser diferentes. Este es el jard√≠n de los senderos que se bifurcan Gelman, que invalida en parte el uso valores p como criterio de evidencia contra la hip√≥tesis nula. Esto es exacerbado por: Tama√±os de muestra chicos y efectos ‚Äúinestables‚Äù que se quieren medir (por ejemplo en sicolog√≠a) El hecho de que el criterio de publicaci√≥n es obtener un valor p &lt; 0.05, y la presi√≥n fuerte sobre los investigadores para producir resultados publicables (p &lt; 0.05) El que estudios o resultados similares que no obtuvieron valores \\(p\\) por debajo del umbral no son publicados o reportados. Ver por ejemplo el comunicado de la ASA. Ojo: esas presiones de publicaci√≥n no s√≥lo ocurre para investigadores en sicolog√≠a. Cuando trabajamos en problemas de an√°lisis de datos en problemas que son de importancia, es com√∫n que existan intereses de algunas partes o personas involucradas por algunos resultados u otros (por ejemplo, nuestros clientes de consultor√≠a o clientes internos). Eso puede da√±ar nuestro trabajo como analistas, y el avance de nuestro equipo. Aunque esas presiones son inevitables, se vuelven manejables cuando hay una relaci√≥n de confianza entre las partes involucradas. Ejemplo: decisiones de an√°lisis y valores p En el ejemplo de datos de fusi√≥n, decidimos probar, por ejemplo, el promedio de los cuartiles inferior y superior, lo cual no es una decisi√≥n t√≠pica pero usamos como ilustraci√≥n. Ahora intentamos usar distintas mediciones de la diferencia entre los grupos, usando distintas medidas resumen y transformaciones (por ejemplo, con o sin logaritmo). Aqu√≠ hay unas 12 combinaciones distintas para hacer el an√°lisis (multiplicadas por criterios de ‚Äúaceptaci√≥n de datos en la muestra‚Äù, que simulamos tomando una submuestra al azar): calc_fusion &lt;- function(stat_fusion, trans, comparacion){ fun &lt;- function(datos){ datos %&gt;% group_by(nv.vv) %&gt;% summarise(est = stat_fusion({{ trans }}(time))) %&gt;% pivot_wider(names_from = nv.vv, values_from = est) %&gt;% mutate(dif = {{ comparacion }}) %&gt;% pull(dif) } fun } valor_p &lt;- function(datos, variable, calc_diferencia, n = 1000){ # calcular estad√≠stica para cada grupo permutar &lt;- function(variable){ sample(variable, length(variable)) } tbl_perms &lt;- tibble(.sample = seq(1, n-1, 1)) %&gt;% mutate(diferencia = map_dbl(.sample, ~ datos %&gt;% mutate({{variable}} := permutar({{variable}})) %&gt;% calc_diferencia)) perms &lt;- bind_rows(tbl_perms, tibble(.sample = n, diferencia = calc_diferencia(datos))) perms_ecdf &lt;- ecdf(perms$diferencia) dif &lt;- calc_diferencia(datos) 2 * min(perms_ecdf(dif), 1- perms_ecdf(dif)) } set.seed(7272) media_cuartiles &lt;- function(x){ (quantile(x, 0.75) + quantile(x, 0.25))/2 } # nota: usar n=10000 o m√°s, esto solo es para demostraci√≥n: ejemplo &lt;- list() calc_dif &lt;- calc_fusion(mean, identity, VV - NV) ejemplo$media_dif &lt;- valor_p(fusion %&gt;% sample_frac(0.95), nv.vv, calc_dif, n = 10000) calc_dif &lt;- calc_fusion(mean, log, VV - NV) ejemplo$media_dif_log &lt;- valor_p(fusion %&gt;% sample_frac(0.95), nv.vv, calc_dif, n = 10000) calc_dif &lt;- calc_fusion(median, identity, VV / NV) ejemplo$mediana_razon &lt;- valor_p(fusion %&gt;% sample_frac(0.95), nv.vv, calc_dif, n = 10000) calc_dif &lt;- calc_fusion(media_cuartiles, identity, VV / NV) ejemplo$cuartiles_razon &lt;- valor_p(fusion %&gt;% sample_frac(0.95), nv.vv, calc_dif, n = 10000) ejemplo &lt;- read_rds(&quot;cache/ejemplo_p_val.rds&quot;) ejemplo$media_dif ## [1] 0.0658 ejemplo$media_dif_log ## [1] 0.018 ejemplo$mediana_razon ## [1] 0.049 ejemplo$cuartiles_razon ## [1] 0.0464 Si existen grados de libertad - muchas veces necesarios para hacer un an√°lisis exitoso-, entonces los valores p pueden tener poco significado. Alternativas o soluciones El primer punto importante es reconocer que la mayor parte de nuestro trabajo es exploratorio (recordemos el proceso complicado del an√°lisis de datos de refinamiento de preguntas). En este tipo de trabajo, reportar valores p puede tener poco sentido, y mucho menos tiene sentido aceptar algo ‚Äúverdadero‚Äù cuando pasa un umbral de significancia dado. Nuestro inter√©s principal al hacer an√°lisis es expresar correctamente y de manera √∫til la incertidumbre asociada a las conclusiones o patrones que mostramos (asociada a variaci√≥n muestral, por ejemplo) para que el proceso de toma de decisiones sea informado. Un resumen de un n√∫mero (valor p, o el que sea) no puede ser tomado como criterio para tomar una decisi√≥n que generalmente es compleja. En la siguiente secci√≥n veremos c√≥mo podemos mostrar parte de esa incertidumbre de manera m√°s √∫til. Por otra parte, los estudios confirmatorios (donde se reportan valores p) tambi√©n tienen un lugar. En √°reas como la sicolog√≠a, existen ahora movimientos fuertes en favor de la repetici√≥n de estudios prometedores pero donde hay sospecha de grados de libertad del investigador. Este movimiento sugiere dar valor a los estudios exploratorios que no reportan valor p, y posteriormente, si el estudio es de inter√©s, puede intentarse una replicaci√≥n confirmatoria, con potencia m√°s alta y con planes de an√°lisis predefinidos. Referencias "],
["tareas.html", "Tareas 1. An√°slisis Exploratorio 2. Loess 3. Tipos de estudio y PGD 4. Pruebas de hip√≥tesis visuales y permutaci√≥n", " Tareas Las tareas se env√≠an por correo a teresa.ortiz.mancera@gmail.com con t√≠tulo: fundamentos-tareaXX (donde XX corresponde al n√∫mero de tarea, 01..). Las tareas deben incluir c√≥digo y resultados (si conocen Rmarkdown es muy conveniente para este prop√≥sito). 1. An√°slisis Exploratorio Realicen los ejercicios del script 01_exploratorio.R que vimos la clase pasada (RStudio.cloud proyecto 01-exploratorio). Escriban las respuestas en un reporte que incluya c√≥digo y resultados (puede ser word, html, pdf,‚Ä¶). 2. Loess La tarea 2 es el proyecto de RStudio.Cloud con este nombre, el ejercicio est√° en un archvio de R Markdown, para los que son nuevos con R Markdown deben escribir su c√≥digo en los bloques de c√≥digo (secciones grises entre ```{r} codigo ```) una vez que escriban sus respuestas pueden generar el reporte tejiendo el documento, para esto deben presionar el bot√≥n Knit. Env√≠en el reporte por correo electr√≥nico (con t√≠tulo fundamentos-tarea02). 3. Tipos de estudio y PGD Para cada uno de los siguientes estudios, ub√≠calos en el recuadro y contesta lo que se pide. Env√≠en las respuestas por correo electr√≥nico (con t√≠tulo fundamentos-tarea03). Inferencia estad√≠stica de acuerdo al tipo del dise√±o (Ramsey and Schafer 2012). En 1930 se realiz√≥ un experimento en 20,000 ni√±os de edad escolar de Inglaterra. Los maestros fueron los responsables de asignar a los ni√±os de manera aleatoria al grupo de tratamiento -que consist√≠a en recibir 350 ml de leche diaria - o al grupo de control, que no recib√≠a suplementos alimenticios. Se registraron peso y talla antes y despu√©s del experimento. El estudio descubri√≥ que los ni√±os que recibieron la leche ganaron m√°s en peso en el lapso del estudio. Una investigaci√≥n posterior descubri√≥ que los ni√±os del grupo control eran de mayor peso y talla que los del grupo de intervenci√≥n, antes de iniciar el tratamiento. ¬øQu√© pudo haber ocurrido? ¬øPodemos utilizar los resultados del estudio para inferir causalidad? Supongamos que de los registros de un conjunto de doctores se slecciona una muestra aleatoria de individuos americanos cauc√°sicos y de americanos de ascendencia china, con el objetivo de comparar la presi√≥n arterial de las dos poblaciones. Supongamos que a los seleccionados se les pregunta si quieren participar y algunos rechazan. Se compara la distribuci√≥n de presi√≥n arterial entre los que accedieron a participar. ¬øEn que cuadro cae este estudio? ¬øQu√© supuesto es necesario para permitir inferencias a las poblaciones muestreadas? Un grupo de investigadores report√≥ que el consumo moderado de alcohol estaba asociado con un menor riesgo de demencia (Mukamal et al. (2003)). Su muestra consist√≠a en 373 personas con demencia y 373 sin demencia. A los participantes se les pregint√≥ cu√°nta cerveza, vino, o licor consum√≠an. Se observ√≥ que aquellos que consum√≠an de 1-6 bebidas por semana ten√≠an una incidencia menor de demencia comparado a aquellos que se absten√≠an del alcohol. ¬øse puede inferir causalidad? Un estudio descubri√≥ que los ni√±os que ven m√°s de dos horas diarias de televisi√≥n tienden a tener mayores niveles de colesterol que los que ven menos de dos horas diarias. ¬øC√≥mo se pueden utilizar estos resultados? M√°s gente se enferma de gripa en temporada de invierno, ¬øesto prueba que las temperaturas bajas ocasionan las gripas? ¬øQu√© otras variables podr√≠an estar involucradas? ¬øCu√°l es la diferencia entre un experimento aleatorizado y una muestra aleatoria? 4. Pruebas de hip√≥tesis visuales y permutaci√≥n La tarea 4 es el proyecto de RStudio.Cloud con este nombre, el ejercicio est√° en un archvio de R Markdown. Env√≠en el reporte por correo electr√≥nico (con t√≠tulo fundamentos-tarea04). Referencias "],
["referencias.html", "Referencias", " Referencias "]
]
